{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/lpodgorsek/mag/scripts')\n",
    "\n",
    "from relationGraph import Relation, RelationGraph, MatrixOfRelationGraph\n",
    "from autoencoder import seedy, AutoEncoder\n",
    "import utilityFunctions as uf\n",
    "from main import test_build_relation_graph_with_symertic_data, test_convert_graph_to_2D_matrix, test_get_matix_for_autoencoder, test_autoencoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from base import load_source\n",
    "from base2 import load_dicty, load_pharma\n",
    "import utilityFunctions as uf\n",
    "import autoencoder as ae\n",
    "import multimodal as mm\n",
    "\n",
    "\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from fastcluster import linkage\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Layer, Reshape, UpSampling2D, Flatten, Masking, Dropout, concatenate, Conv2D, MaxPooling2D, BatchNormalization, Lambda\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, History\n",
    "from tensorflow import set_random_seed\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "\n",
    "folder = '/home/lpodgorsek/data/cnn/dicty/_061/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_N_cells(data, num_of_cells):\n",
    "    # data = (1,1024,128,1)\n",
    "    # num_of_cells = 10\n",
    "    _,row,col,_ = data.shape\n",
    "    data_flatten = data.flatten()\n",
    "    rand_vector = np.random.choice(np.flatnonzero(data_flatten), num_of_cells, replace=False)\n",
    "    removed_cells = []\n",
    "    \n",
    "    for i in range(len(rand_vector)):\n",
    "        v = data_flatten[rand_vector[i]]\n",
    "        # removed_cells = [(100,1), (223, 1), (2244, 1), ...]\n",
    "        removed_cells.append((rand_vector[i], v))\n",
    "    return removed_cells\n",
    "\n",
    "def save_test_cells(filename, data):\n",
    "    f = uf.my_savez(filename)\n",
    "    f.savez(data)\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "def load_test_cells(filename):\n",
    "    f = np.load(filename)\n",
    "    data = f[f.files[0]]\n",
    "    new_data = []\n",
    "    for line in data:\n",
    "        new_data.append((int(line[0]), line[1]))\n",
    "        \n",
    "    return new_data\n",
    "\n",
    "\n",
    "def split_data(data, validation=.7, test=.3):\n",
    "    if validation + test != 1:\n",
    "        raise ValueError('Sum  of validation (' + str(validation) + ') and test(' + str(test) + ') is not equal 1')\n",
    "        \n",
    "    data = np.asarray(data)\n",
    "    v = int(len(data) * validation)\n",
    "    t = int(len(data) * test)\n",
    "    \n",
    "    return data[:v], data[-t:]\n",
    "    \n",
    "\n",
    "\n",
    "def remove_cells_from_data(data, list_of_cells):\n",
    "    # data = (1,1024,128,1)\n",
    "    # list_of_cells = [(111, 1.0), (2244, 0.34), ...]\n",
    "    _,row,col,_ = data.shape\n",
    "    data_flatten = data.flatten()\n",
    "    for index, _ in list_of_cells:\n",
    "        data_flatten[int(index)] = 0\n",
    "        \n",
    "    return data_flatten.reshape(1, row, col, 1)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "def data_generator(filenames, org_data, batch_size=1, testing_cells=None, removed_cells=False):\n",
    "    # n_pack => 1 samples of matrix\n",
    "    # n_pack = batch_size\n",
    "    # org_data = [[1,1024,128,1], [1,1024,256,1], [1,1024,1024,1]]\n",
    "    # testing_cells = [[(111, 1.0), (2244, 0.34), ...], [(111, 1.0), (2244, 0.34), ...], ...]\n",
    "    \n",
    "    files = []              # different files\n",
    "    num_packs = []          # subpacked inside of file\n",
    "    for filename in filenames:\n",
    "        f = np.load(filename)\n",
    "        files.append(f)  \n",
    "        num_packs.append(f.files)\n",
    "    \n",
    "    counter = 0\n",
    "    while True:\n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(len(files)):\n",
    "            _x = []\n",
    "            _y = []\n",
    "            for j in range(batch_size):\n",
    "                rand_num = np.random.randint(len(num_packs[i]))\n",
    "                f = files[i]\n",
    "                pack = num_packs[i]\n",
    "                data = f[pack[rand_num]] \n",
    "                \n",
    "                if testing_cells is not None and removed_cells:\n",
    "                    data = remove_cells_from_data(data, testing_cells[i])\n",
    "\n",
    "                _, row, col, _ = data.shape\n",
    "                if col != 1021:\n",
    "                    _x.append(f[pack[rand_num]])\n",
    "                    _y.append(org_data[i])\n",
    "            \n",
    "            _x = np.asarray(_x)\n",
    "            _y = np.asarray(_y)\n",
    "\n",
    "            _x = _x[:, 0, :, :, :]\n",
    "            _y = _y[:, 0, :, :, :]\n",
    "        \n",
    "            x.append(_x)\n",
    "            y.append(_y)\n",
    "            \n",
    "        yield (x, y)\n",
    "        \n",
    "            \n",
    "def top_N_rows(data, rows=100):\n",
    "    _, row, col, _ = data.shape\n",
    "    rows = row\n",
    "    remove_col = col % 6\n",
    "    data = data.reshape(row, col)\n",
    "    new_data = data[:rows, :(col - remove_col)]\n",
    "    return new_data.reshape(1, rows, col - remove_col, 1)\n",
    "    \n",
    "    \n",
    "def shuffle_data(org_data):\n",
    "    shufle_data = []\n",
    "    for data in org_data:\n",
    "        tmp_data = data\n",
    "        _, row, col, _ = tmp_data.shape\n",
    "        tmp_data = tmp_data.flatten()\n",
    "        np.random.shuffle(tmp_data)  # shuffle org data\n",
    "        shufle_data.append(np.array(tmp_data).reshape(1, row, col, 1))\n",
    "\n",
    "    return shufle_data\n",
    "\n",
    "\n",
    "def replace_and_shuffle_data_with_random(org_data):\n",
    "    shufle_data = []\n",
    "    for data in org_data:\n",
    "        tmp_data = data\n",
    "        _, row, col, _ = tmp_data.shape\n",
    "        tmp_data = tmp_data.flatten()\n",
    "        tmp_data[tmp_data > 0] = 1;   # set nonzero values to 1\n",
    "        tmp_data = tmp_data * np.random.rand(len(tmp_data))  # multiply with random vecotor\n",
    "        shufle_data.append(np.array(tmp_data).reshape(1, row, col, 1))\n",
    "\n",
    "    return shufle_data\n",
    "\n",
    "    \n",
    "def order_inputs(model, org_data):\n",
    "    new_order_data = []\n",
    "    for inp in model.inputs:\n",
    "        _, x, y, _ = inp.shape\n",
    "        for data in org_data:\n",
    "            _, row, col, _ = data.shape\n",
    "            if x == row and y == col:\n",
    "                new_order_data.append(np.array(data).reshape(1,row,col,1))\n",
    "                break\n",
    "\n",
    "    return new_order_data\n",
    "\n",
    "\n",
    "def duplicateBatchData(data, batch=2):\n",
    "    new_data = []\n",
    "    for i in range(len(data)):\n",
    "        b = []\n",
    "        for j in range(batch):\n",
    "            b.append(data[i])\n",
    "\n",
    "        b = np.asarray(b)\n",
    "        b = b[:,0,:,:,:]\n",
    "\n",
    "        new_data.append(b)\n",
    "        \n",
    "    return new_data;\n",
    "\n",
    "    \n",
    "class MultiModal:\n",
    "    \n",
    "    def __init__(self, graph=None, path='', num_of_test_cells=10, load_test_cells=False):\n",
    "        self.input_visibles = []\n",
    "        self.input_layers = []\n",
    "        self.outputs_layers = []\n",
    "        self.input_data_size = []\n",
    "        self.filenames = []\n",
    "        self.inputs = None\n",
    "        self.model = None\n",
    "        self.path = path\n",
    "        self.folder = path\n",
    "        self.graph = graph\n",
    "        self.org_data = []\n",
    "        self.predict_data = []\n",
    "        self.base_line = []\n",
    "        self.shuffled_data = []\n",
    "        self.dropout = 0.5\n",
    "        self.num_of_saved_cells = num_of_test_cells\n",
    "        self.saved_cells_for_test = []\n",
    "        self.saved_cells_for_validation = []\n",
    "        self.predict_saved_cells_for_test = []\n",
    "        self.is_first_iteration = True\n",
    "        self.fake_org_data = []\n",
    "        self.activation = 'relu'\n",
    "        self.load_test_cells = load_test_cells\n",
    "        \n",
    "        if graph is not None:\n",
    "            self._read_graph(graph)\n",
    "        self._callbacks()\n",
    "        \n",
    "        for i in range(len(self.org_data)):\n",
    "            self.fake_org_data.append(remove_cells_from_data(self.org_data[i], self.saved_cells_for_test[i]))\n",
    "                    \n",
    "    def _read_graph(self, graph):\n",
    "        already = set()\n",
    "        for obj in graph.objects.values():        \n",
    "            for relation in obj.relation_x:\n",
    "                if relation.name not in already:\n",
    "                    self._set_params(relation)\n",
    "                    already.add(relation.name)\n",
    "\n",
    "            for relation in obj.relation_y:\n",
    "                if relation.name not in already:\n",
    "                    self._set_params(relation)\n",
    "                    already.add(relation.name)\n",
    "                    \n",
    "    def set_path_to_files(self, path):\n",
    "        self.path = path\n",
    "        self.filenames = []\n",
    "        already = set()\n",
    "        for obj in self.graph.objects.values():        \n",
    "            for relation in obj.relation_x:\n",
    "                if relation.name not in already:\n",
    "                    self.filenames.append(self.path + relation.name + '.npz')\n",
    "                    already.add(relation.name)\n",
    "\n",
    "            for relation in obj.relation_y:\n",
    "                if relation.name not in already:\n",
    "                    self.filenames.append(self.path + relation.name + '.npz')\n",
    "                    already.add(relation.name)\n",
    "                    \n",
    "    def set_path_to_folder(self, folder):\n",
    "        self.folder = folder\n",
    "                        \n",
    "    def _set_params(self, relation):\n",
    "        print(relation.name + '\\t' + str(relation.matrix.shape))\n",
    "        \n",
    "        row, col = relation.matrix.shape\n",
    "        \n",
    "        data = np.array(relation.matrix).reshape(1,row,col,1)\n",
    "#         new_data = top_N_rows(data)\n",
    "        new_data = data\n",
    "        _, new_r, new_c, _ = new_data.shape\n",
    "        self.org_data.append(new_data)\n",
    "        if self.load_test_cells == True:\n",
    "            test_cells = load_test_cells(self.folder + 'samples_' + relation.name + '.npz')\n",
    "            validation_cells, test_cells = split_data(test_cells)\n",
    "            self.saved_cells_for_validation.append(validation_cells)\n",
    "            self.saved_cells_for_test.append(test_cells)\n",
    "            self.num_of_saved_cells = len(test_cells)\n",
    "        else:\n",
    "            test_cells = select_N_cells(new_data, self.num_of_saved_cells)\n",
    "            self.saved_cells_for_test.append(test_cells)\n",
    "            save_test_cells(self.folder + 'samples_' + relation.name, test_cells)\n",
    "        self.input_data_size.append((new_r, new_c))\n",
    "        self._input_layer((new_r, new_c))\n",
    "        self.filenames.append(self.path + relation.name + '.npz')\n",
    "        \n",
    "    def _input_layer(self, input_size):\n",
    "        row, col = input_size\n",
    "        visible = Input(shape=(row, col, 1))\n",
    "#         Conv2D filtered by columns\n",
    "        \n",
    "        layer = Conv2D(128, (3, 3), activation=self.activation, padding='same')(visible)\n",
    "#         layer = Conv2D(128, (3, 3), activation='relu', padding='same')(layer)\n",
    "        layer = MaxPooling2D((2, 2), padding='same')(layer)\n",
    "        layer = Conv2D(64, (3, 3), activation=self.activation, padding='same')(layer)\n",
    "#         layer = Conv2D(64, (3, 3), activation='relu', padding='same')(layer)\n",
    "        layer = MaxPooling2D((2, 2), padding='same')(layer)\n",
    "        layer = Conv2D(32, (3, 3), activation=self.activation, padding='same')(layer)\n",
    "#         layer = Conv2D(32, (3, 3), activation='relu', padding='same')(layer)\n",
    "        layer = MaxPooling2D((2, 2), padding='same')(layer)\n",
    "        layer = Conv2D(16, (3, 3), activation=self.activation, padding='same')(layer)\n",
    "#         layer = Conv2D(16, (3, 3), activation='relu', padding='same')(layer)\n",
    "        layer = MaxPooling2D((2, 2), padding='same')(layer)\n",
    "        if col == 1024:\n",
    "            layer = Conv2D(8, (3, 3), activation=self.activation, padding='same')(layer)\n",
    "#             layer = Conv2D(8, (3, 3), activation='relu', padding='same')(layer)\n",
    "#             layer = MaxPooling2D((2, 2), padding='same')(layer)\n",
    "            \n",
    "        layer = Flatten()(layer)\n",
    "        layer = Dense(1024, activation=self.activation)(layer)\n",
    "        layer = Dropout(self.dropout)(layer)\n",
    "        layer = Dense(512, activation=self.activation)(layer)\n",
    "        layer = Dropout(self.dropout)(layer)\n",
    "        layer = Dense(256, activation=self.activation)(layer)\n",
    "        layer = Dropout(self.dropout)(layer)\n",
    "        layer = Dense(128, activation=self.activation)(layer)\n",
    "        layer = Dropout(self.dropout)(layer)\n",
    "        layer = Dense(64, activation=self.activation)(layer)\n",
    "        \n",
    "        self.input_layers.append(layer)\n",
    "        self.input_visibles.append(visible)\n",
    "    \n",
    "    def _output_layer(self, input_size):\n",
    "        row, col = input_size\n",
    "        layer = None\n",
    "        \n",
    "        if col == 128:\n",
    "            layer = Reshape((64, 8, 2))(self.inputs)\n",
    "        elif col == 256:\n",
    "            layer = Reshape((64, 16, 1))(self.inputs)\n",
    "        elif col == 1024:\n",
    "            layer = Reshape((32, 32, 1))(self.inputs)\n",
    "            layer = Conv2D(8, (3, 3), activation=self.activation, padding='same')(layer)\n",
    "            layer = UpSampling2D((2, 2))(layer)\n",
    "        \n",
    "        layer = Conv2D(16, (3, 3), activation=self.activation, padding='same')(layer)\n",
    "        layer = UpSampling2D((2, 2))(layer)\n",
    "        layer = Conv2D(32, (3, 3), activation=self.activation, padding='same')(layer)\n",
    "        layer = UpSampling2D((2, 2))(layer)\n",
    "        layer = Conv2D(64, (3, 3), activation=self.activation, padding='same')(layer)\n",
    "        layer = UpSampling2D((2, 2))(layer)\n",
    "        layer = Conv2D(128, (3, 3), activation=self.activation, padding='same')(layer)\n",
    "        layer = UpSampling2D((2, 2))(layer)\n",
    "        layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(layer)\n",
    "\n",
    "        self.outputs_layers.append(layer)\n",
    "        \n",
    "    def _decoder(self):\n",
    "        layer = Dense(128, activation=self.activation)(self.inputs)\n",
    "        layer = Dropout(self.dropout)(layer)\n",
    "        layer = Dense(256, activation=self.activation)(layer)\n",
    "        layer = Dropout(self.dropout)(layer)\n",
    "        layer = Dense(512, activation=self.activation)(layer)\n",
    "        layer = Dropout(self.dropout)(layer)\n",
    "        layer = Dense(1024, activation=self.activation)(layer) \n",
    "        self.inputs = layer\n",
    "        \n",
    "    def _callbacks(self):\n",
    "        log_dir = '/home/lpodgorsek/data/logs/'\n",
    "        self.callbacks = [\n",
    "            TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_images=True)\n",
    "#             EarlyStopping(monitor='loss', min_delta=0, patience=3, verbose=0, mode='auto'),\n",
    "            \n",
    "        ]\n",
    "        \n",
    "    def build_model(self, optimizer='sgd', loss='mse', metrics=['mae', 'acc'], gpu=1):\n",
    "        self.inputs = concatenate(self.input_layers)\n",
    "        self.inputs = Dense(64, activation=self.activation)(self.inputs) \n",
    "#         layer = concatenate(self.input_layers)\n",
    "#         layer = Dense(512, activation=self.activation)(layer)\n",
    "#         layer = Dropout(self.dropout)(layer)\n",
    "#         layer = Dense(256, activation=self.activation)(layer)\n",
    "#         layer = Dropout(self.dropout)(layer)\n",
    "#         layer = Dense(128, activation=self.activation)(layer)\n",
    "#         layer = Dropout(self.dropout)(layer)\n",
    "#         layer = Dense(64, activation=self.activation)(layer)\n",
    "#         self.inputs = layer\n",
    "        self._decoder()\n",
    "\n",
    "        [self._output_layer(data_size) for data_size in self.input_data_size]\n",
    "        \n",
    "        self.model = Model(inputs=self.input_visibles, outputs=self.outputs_layers)\n",
    "        \n",
    "        try:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.model = multi_gpu_model(self.model, gpus=gpu, cpu_merge=True, cpu_relocation=True)\n",
    "        except e:\n",
    "            print(e)\n",
    "            pass\n",
    "        \n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "        self.model.summary()\n",
    "        \n",
    "    def fit(self, batch_size, epochs):\n",
    "        self.batch_size = batch_size;\n",
    "        self.model.fit_generator(\n",
    "            data_generator(self.filenames, self.fake_org_data, batch_size, self.saved_cells_for_test, self.is_first_iteration), \n",
    "            steps_per_epoch=batch_size, \n",
    "            epochs=epochs,\n",
    "            callbacks=self.callbacks\n",
    "        )\n",
    "        \n",
    "    def save(self, path, version):\n",
    "        self.model.save(path + 'experiment_' + version + '.h5')\n",
    "\n",
    "    def load_model(self, path, version):\n",
    "        self.model = load_model(path + 'experiment_' + version + '.h5')\n",
    "        \n",
    "    def predict_hidden_cells(self, display_cells=None):\n",
    "        list_of_predict = {}\n",
    "            \n",
    "#         if display_cells is None or display_cells > len(self.saved_cells_for_test[0]):\n",
    "#             display_cells = len(self.saved_cells_for_test[0])\n",
    "            \n",
    "        print()\n",
    "        print(\"Predict Original Diff \\t\\tPredict Original Diff \\t\\tPredict Original Diff\")\n",
    "#         print(\"---------------------------------------------------------------------------------------\")\n",
    "        avg_diff_valid = np.zeros(len(self.saved_cells_for_validation))\n",
    "        for i in range(len(self.saved_cells_for_validation[0])):\n",
    "            for j in range(len(self.saved_cells_for_validation)):\n",
    "                idx, val = self.saved_cells_for_validation[j][i]\n",
    "                idx = int(idx)\n",
    "                predict_val = self.predict_data[j].flatten()[idx]\n",
    "                diff_abs = np.abs(self.predict_data[j].flatten()[idx] - val)\n",
    "                avg_diff_valid[j] += diff_abs\n",
    "                \n",
    "                if j not in list_of_predict:\n",
    "                    list_of_predict[j] = [(idx, predict_val)] \n",
    "                else:\n",
    "                    list_of_predict[j].append((idx, predict_val)) \n",
    "                    \n",
    "        print(\"---------------------------------------------------------------------------------------\")\n",
    "        print(\"VALIDATION: \" + str(len(self.saved_cells_for_validation[0])), end=\"\")\n",
    "        for i in range(len(avg_diff_valid)):\n",
    "            val = avg_diff_valid[i]*100/len(self.saved_cells_for_validation[0])\n",
    "            print(\"\\t\\t\" + format(val, '.5f') + \"%\", end=\"\\t\")\n",
    "        print()\n",
    "    \n",
    "    \n",
    "        avg_diff = np.zeros(len(self.saved_cells_for_test))\n",
    "        for i in range(len(self.saved_cells_for_test[0][:display_cells])):\n",
    "            for j in range(len(self.saved_cells_for_test)):\n",
    "                idx, val = self.saved_cells_for_test[j][i]\n",
    "                idx = int(idx)\n",
    "                predict_val = self.predict_data[j].flatten()[idx]\n",
    "                diff_abs = np.abs(self.predict_data[j].flatten()[idx] - val)\n",
    "                avg_diff[j] += diff_abs\n",
    "                \n",
    "                if j not in list_of_predict:\n",
    "                    list_of_predict[j] = [(idx, predict_val)] \n",
    "                else:\n",
    "                    list_of_predict[j].append((idx, predict_val)) \n",
    "#                 print(str(self.saved_cells_for_test[j][i]) + ' ' + format(predict_val, '.5f') + ' ' + format(val, '.5f') + ' ' + format(diff_abs, '.5f'), end=\" \\t\")\n",
    "#             print()\n",
    "        print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "        print(\"TEST: \" + str(len(self.saved_cells_for_test[0])), end=\"\")\n",
    "        for i in range(len(avg_diff)):\n",
    "            val = avg_diff[i]*100/len(self.saved_cells_for_test[0])\n",
    "            print(\"\\t\\t\" + format(val, '.5f') + \"%\", end=\"\\t\")\n",
    "        print()\n",
    "        \n",
    "        for i in range(len(list_of_predict)):\n",
    "            self.predict_saved_cells_for_test.append(list_of_predict[i])\n",
    "        \n",
    "    def predict_generator(self, batch_size=10, iteration=1):\n",
    "        predict = self.model.predict_generator(\n",
    "            data_generator(self.filenames, self.fake_org_data, batch_size, self.is_first_iteration),\n",
    "            steps=100\n",
    "        )\n",
    "        \n",
    "        self.is_first_iteration = False\n",
    "\n",
    "        for i in range(len(self.org_data)):\n",
    "            _,row, col,_ = predict[i].shape\n",
    "            print(predict[i].shape)\n",
    "            mse = 0\n",
    "            for j in range(predict[i].shape[0]):\n",
    "                mse += mean_squared_error(self.org_data[i].flatten(), predict[i][j].flatten())\n",
    "\n",
    "            print('MSE' + str(i+1) + ': ' + format(mse*100/predict[i].shape[0], '.5f'))\n",
    "            print()\n",
    "\n",
    "            if col == 128:\n",
    "                filename = self.folder + 'predict_' + str(iteration) + '_ann.npz'\n",
    "            elif col == 256:\n",
    "                filename = self.folder + 'predict_' + str(iteration) + '_expr.npz'\n",
    "            elif col == 1024:\n",
    "                filename = self.folder + 'predict_' + str(iteration) + '_ppi.npz'\n",
    "            else:\n",
    "                raise ValueError(\"ERROR: wrong data!!\")\n",
    "                \n",
    "            f = uf.my_savez(filename)\n",
    "\n",
    "            for j in range(predict[i].shape[0]):\n",
    "                data = predict[i][j].reshape(1, row, col, 1)\n",
    "                f.savez(data)\n",
    "            f.close()\n",
    "        \n",
    "    def predict(self, random=False):\n",
    "        self.org_data = order_inputs(self.model, self.org_data)\n",
    "            \n",
    "        if random == True:\n",
    "            self.shuffled_data = replace_and_shuffle_data_with_random(self.org_data)\n",
    "        else: \n",
    "            self.shuffled_data = shuffle_data(self.org_data)\n",
    "            \n",
    "        self.predict_data = self.model.predict(self.org_data)\n",
    "        self.base_line = self.model.predict(self.shuffled_data)\n",
    "        outputHeader = 'Data\\t\\t'\n",
    "        outputHeader += 'Density\\t\\t'\n",
    "        outputHeader += 'Predict\\t\\t'\n",
    "        outputHeader += 'BaseLine\\t'\n",
    "        outputHeader += 'AVG Mean\\t'\n",
    "        outputHeader += 'Predict (mean)\\t'\n",
    "        outputHeader += 'Predict (min)\\t'\n",
    "        outputHeader += 'Predict (max)\\t'\n",
    "        print(outputHeader)\n",
    "        \n",
    "#         print('Data \\t\\t\\tDensity \\tPredict \\tBaseLine \\tAVG Mean')\n",
    "        for i in range(len(self.org_data)):\n",
    "            _, row, col, _ = self.org_data[i].shape \n",
    "            mse = mean_squared_error(self.org_data[i].flatten(), self.predict_data[i].flatten())\n",
    "            mse_base_line = mean_squared_error(self.shuffled_data[i].flatten(), self.base_line[i].flatten())\n",
    "            \n",
    "            non_zeros = self.org_data[i].flatten()\n",
    "            non_zeros[self.org_data[i].flatten() > 0] = 1\n",
    "            org_mean = round(np.mean(non_zeros * self.org_data[i].flatten()), 5)\n",
    "            predict_mean = round(np.mean(non_zeros * self.predict_data[i].flatten()), 5)\n",
    "            \n",
    "            outputBody = '(' + str(row) + ',' + str(col) + ') ' + '\\t'\n",
    "            outputBody += str(round((np.count_nonzero(self.org_data[i])/(row * col)) * 100, 2)) + '% \\t\\t'\n",
    "            outputBody += str(round(mse * 100, 5)) + '% \\t'\n",
    "            outputBody += str(round(mse_base_line * 100, 5)) + '% '+ '\\t'\n",
    "            outputBody += str(org_mean) + '\\t\\t'\n",
    "            outputBody += str(predict_mean) + '\\t\\t'\n",
    "            outputBody += str(round(min(self.predict_data[i].flatten()), 5)) + '\\t\\t'\n",
    "            outputBody += str(round(max(self.predict_data[i].flatten()), 5)) + '\\t'\n",
    "            print(outputBody)\n",
    "            \n",
    "    def predictMultiGPU(self, random=False, gpu=1):\n",
    "        self.org_data = order_inputs(self.model, self.org_data)\n",
    "            \n",
    "        if random == True:\n",
    "            self.shuffled_data = replace_and_shuffle_data_with_random(self.org_data)\n",
    "        else: \n",
    "            self.shuffled_data = shuffle_data(self.org_data)\n",
    "            \n",
    "        outputHeader = 'Data\\t\\t'\n",
    "        outputHeader += 'Density\\t\\t'\n",
    "        outputHeader += 'Predict\\t\\t'\n",
    "        outputHeader += 'BaseLine\\t'\n",
    "        outputHeader += 'AVG Mean\\t'\n",
    "        outputHeader += 'Predict (mean)\\t'\n",
    "        outputHeader += 'Predict (min)\\t'\n",
    "        outputHeader += 'Predict (max)\\t'\n",
    "        print(outputHeader)\n",
    "        \n",
    "        if gpu == 1:\n",
    "            self.predict_data = self.model.predict(self.org_data)\n",
    "            self.base_line = self.model.predict(self.shuffled_data)\n",
    "\n",
    "    #         print('Data \\t\\t\\tDensity \\tPredict \\tBaseLine \\tAVG Mean')\n",
    "            for i in range(len(self.org_data)):\n",
    "                _, row, col, _ = self.org_data[i].shape \n",
    "                mse = mean_squared_error(self.org_data[i].flatten(), self.predict_data[i].flatten())\n",
    "                mse_base_line = mean_squared_error(self.shuffled_data[i].flatten(), self.base_line[i].flatten())\n",
    "\n",
    "                non_zeros = self.org_data[i].flatten()\n",
    "                non_zeros[self.org_data[i].flatten() > 0] = 1\n",
    "                org_mean = round(np.mean(non_zeros * self.org_data[i].flatten()), 5)\n",
    "                predict_mean = round(np.mean(non_zeros * self.predict_data[i].flatten()), 5)\n",
    "\n",
    "                outputBody = '(' + str(row) + ',' + str(col) + ') ' + '\\t'\n",
    "                outputBody += str(round((np.count_nonzero(self.org_data[i])/(row * col)) * 100, 2)) + '% \\t\\t'\n",
    "                outputBody += str(round(mse * 100, 5)) + '% \\t'\n",
    "                outputBody += str(round(mse_base_line * 100, 5)) + '% '+ '\\t'\n",
    "                outputBody += str(org_mean) + '\\t\\t'\n",
    "                outputBody += str(predict_mean) + '\\t\\t'\n",
    "                outputBody += str(round(min(self.predict_data[i].flatten()), 5)) + '\\t\\t'\n",
    "                outputBody += str(round(max(self.predict_data[i].flatten()), 5)) + '\\t'\n",
    "                print(outputBody)\n",
    "                \n",
    "        else:            \n",
    "            self.predict_data = self.model.predict(duplicateBatchData(self.org_data, gpu))\n",
    "            self.base_line = self.model.predict(duplicateBatchData(self.shuffled_data, gpu))\n",
    "            \n",
    "    #         print('Data \\t\\t\\tDensity \\tPredict \\tBaseLine \\tAVG Mean')\n",
    "            for i in range(len(self.org_data)):\n",
    "                _, row, col, _ = self.org_data[i].shape \n",
    "                mse = mean_squared_error(self.org_data[i][0].flatten(), self.predict_data[i][0].flatten())\n",
    "                mse_base_line = mean_squared_error(self.shuffled_data[i][0].flatten(), self.base_line[i][0].flatten())\n",
    "\n",
    "                non_zeros = self.org_data[i][0].flatten()\n",
    "                non_zeros[self.org_data[i][0].flatten() > 0] = 1\n",
    "                org_mean = round(np.mean(non_zeros * self.org_data[i][0].flatten()), 5)\n",
    "                predict_mean = round(np.mean(non_zeros * self.predict_data[i][0].flatten()), 5)\n",
    "\n",
    "                outputBody = '(' + str(row) + ',' + str(col) + ') ' + '\\t'\n",
    "                outputBody += str(round((np.count_nonzero(self.org_data[i][0])/(row * col)) * 100, 2)) + '% \\t\\t'\n",
    "                outputBody += str(round(mse * 100, 5)) + '% \\t'\n",
    "                outputBody += str(round(mse_base_line * 100, 5)) + '% '+ '\\t'\n",
    "                outputBody += str(org_mean) + '\\t\\t'\n",
    "                outputBody += str(predict_mean) + '\\t\\t'\n",
    "                outputBody += str(round(min(self.predict_data[i][0].flatten()), 5)) + '\\t\\t'\n",
    "                outputBody += str(round(max(self.predict_data[i][0].flatten()), 5)) + '\\t'\n",
    "                print(outputBody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MultiModal at 0x7f9c8cd97d30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numOfExperiment = 'model_weigth'\n",
    "epchos = 5\n",
    "GPU = 3\n",
    "batch_size = 3 * GPU\n",
    "# path_data = '/data/samples/multiple_inputs_clustering/dicty/'\n",
    "# folder = '/home/lpodgorsek/data/cnn/dicty/_00/'\n",
    "#     folder = '/home/lpodgorsek/data/cnn/dicty/_05/'\n",
    "    folder = '/home/lpodgorsek/data/cnn/dicty/_10/'\n",
    "#     folder = '/home/lpodgorsek/data/cnn/dicty/_25/'\n",
    "#     folder = '/home/lpodgorsek/data/cnn/dicty/_50/'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, num_of_test_cells=100, load_test_cells=False)\n",
    "#     model.build_model(optimizer='sgd', loss='mse')\n",
    "#     loss='binary_crossentropy'\n",
    "model.build_model(optimizer='adadelta', loss='binary_crossentropy', metrics=['mae', 'acc'], gpu=GPU)\n",
    "model.fit(batch_size, epchos)\n",
    "model.save(folder, str(numOfExperiment) + '_1')\n",
    "model.predictMultiGPU(random=False, gpu=GPU)\n",
    "model.predict_hidden_cells()\n",
    "model.predict_generator(batch_size, 1)\n",
    "\n",
    "model.set_path_to_files(folder + 'predict_1_')\n",
    "model.fit(batch_size, epchos)\n",
    "model.save(folder, str(numOfExperiment) + '_2')\n",
    "model.predictMultiGPU(random=False, gpu=GPU)\n",
    "model.predict_hidden_cells()\n",
    "model.predict_generator(batch_size, 2)\n",
    "\n",
    "model.set_path_to_files(folder + 'predict_2_')\n",
    "model.fit(batch_size, epchos)\n",
    "model.save(folder, str(numOfExperiment) + '_3')\n",
    "model.predictMultiGPU(random=False, gpu=GPU)\n",
    "model.predict_hidden_cells()\n",
    "model.predict_generator(batch_size, 3)\n",
    "\n",
    "model.set_path_to_files(folder + 'predict_3_')\n",
    "model.fit(batch_size, epchos)\n",
    "model.save(folder, str(numOfExperiment))\n",
    "model.predictMultiGPU(random=False, gpu=GPU)\n",
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "-------------RelationGraph-------------\n",
      "Gene\t1024\n",
      "3\tann-(1024, 128), expr-(1024, 256), ppi-(1024, 1024)\n",
      "0\t\n",
      "GO term\t128\n",
      "0\t\n",
      "1\tann-(1024, 128)\n",
      "Experimental condition\t256\n",
      "0\t\n",
      "1\texpr-(1024, 256)\n",
      "\n",
      "ann\t(1024, 128)\n",
      "expr\t(1024, 256)\n",
      "ppi\t(1024, 1024)\n",
      "Data\t\tDensity\t\tPredict\t\tBaseLine\tAVG Mean\tPredict (mean)\tPredict (min)\tPredict (max)\t\n",
      "(1024,128) \t4.89% \t\t3.61588% \t5.39172% \t0.04888\t\t0.01235\t\t0.0007\t\t0.52052\t\n",
      "(1024,256) \t95.4% \t\t3.80111% \t4.23938% \t0.82382\t\t0.7003\t\t0.56324\t\t0.79439\t\n",
      "(1024,1024) \t3.04% \t\t2.07006% \t2.20625% \t0.02452\t\t0.0024\t\t0.01013\t\t0.42458\t\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_1')\n",
    "model.predictMultiGPU(random=False, gpu=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict Original Diff \t\tPredict Original Diff \t\tPredict Original Diff\n",
      "---------------------------------------------------------------------------------------\n",
      "VALIDATION: 700\t\t74.58706%\t\t\t12.87520%\t\t\t73.96703%\t\n",
      "---------------------------------------------------------------------------------------\n",
      "TEST: 300\t\t75.02725%\t\t\t13.06100%\t\t\t72.77672%\t\n"
     ]
    }
   ],
   "source": [
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "-------------RelationGraph-------------\n",
      "Gene\t1024\n",
      "3\tann-(1024, 128), expr-(1024, 256), ppi-(1024, 1024)\n",
      "0\t\n",
      "GO term\t128\n",
      "0\t\n",
      "1\tann-(1024, 128)\n",
      "Experimental condition\t256\n",
      "0\t\n",
      "1\texpr-(1024, 256)\n",
      "\n",
      "ann\t(1024, 128)\n",
      "expr\t(1024, 256)\n",
      "ppi\t(1024, 1024)\n",
      "Data\t\tDensity\t\tPredict\t\tBaseLine\tAVG Mean\tPredict (mean)\tPredict (min)\tPredict (max)\t\n",
      "(1024,128) \t4.89% \t\t3.22423% \t5.72095% \t0.04888\t\t0.01563\t\t0.00021\t\t0.79077\t\n",
      "(1024,256) \t95.4% \t\t0.97812% \t6.38311% \t0.82382\t\t0.77335\t\t0.0461\t\t0.85999\t\n",
      "(1024,1024) \t3.04% \t\t2.03284% \t2.32583% \t0.02452\t\t0.00332\t\t0.00467\t\t0.41576\t\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_2')\n",
    "model.predictMultiGPU(random=False, gpu=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict Original Diff \t\tPredict Original Diff \t\tPredict Original Diff\n",
      "---------------------------------------------------------------------------------------\n",
      "VALIDATION: 700\t\t67.96347%\t\t\t6.02034%\t\t\t70.92905%\t\n",
      "---------------------------------------------------------------------------------------\n",
      "TEST: 300\t\t68.76027%\t\t\t5.97439%\t\t\t69.89994%\t\n"
     ]
    }
   ],
   "source": [
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "-------------RelationGraph-------------\n",
      "Gene\t1024\n",
      "3\tann-(1024, 128), expr-(1024, 256), ppi-(1024, 1024)\n",
      "0\t\n",
      "GO term\t128\n",
      "0\t\n",
      "1\tann-(1024, 128)\n",
      "Experimental condition\t256\n",
      "0\t\n",
      "1\texpr-(1024, 256)\n",
      "\n",
      "ann\t(1024, 128)\n",
      "expr\t(1024, 256)\n",
      "ppi\t(1024, 1024)\n",
      "Data\t\tDensity\t\tPredict\t\tBaseLine\tAVG Mean\tPredict (mean)\tPredict (min)\tPredict (max)\t\n",
      "(1024,128) \t4.89% \t\t3.11638% \t5.474% \t0.04888\t\t0.01317\t\t0.0\t\t0.83667\t\n",
      "(1024,256) \t95.4% \t\t0.70409% \t6.01705% \t0.82382\t\t0.82736\t\t0.05649\t\t0.9198\t\n",
      "(1024,1024) \t3.04% \t\t1.95588% \t2.16504% \t0.02452\t\t0.0018\t\t9e-05\t\t0.37719\t\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_3')\n",
    "model.predictMultiGPU(random=False, gpu=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict Original Diff \t\tPredict Original Diff \t\tPredict Original Diff\n",
      "---------------------------------------------------------------------------------------\n",
      "VALIDATION: 700\t\t72.81406%\t\t\t3.65440%\t\t\t75.64895%\t\n",
      "---------------------------------------------------------------------------------------\n",
      "TEST: 300\t\t73.78038%\t\t\t3.57625%\t\t\t74.49604%\t\n"
     ]
    }
   ],
   "source": [
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "-------------RelationGraph-------------\n",
      "Gene\t1024\n",
      "3\tann-(1024, 128), expr-(1024, 256), ppi-(1024, 1024)\n",
      "0\t\n",
      "GO term\t128\n",
      "0\t\n",
      "1\tann-(1024, 128)\n",
      "Experimental condition\t256\n",
      "0\t\n",
      "1\texpr-(1024, 256)\n",
      "\n",
      "ann\t(1024, 128)\n",
      "expr\t(1024, 256)\n",
      "ppi\t(1024, 1024)\n",
      "Data\t\tDensity\t\tPredict\t\tBaseLine\tAVG Mean\tPredict (mean)\tPredict (min)\tPredict (max)\t\n",
      "(1024,128) \t4.89% \t\t2.87473% \t5.70518% \t0.04888\t\t0.01572\t\t0.0\t\t0.89257\t\n",
      "(1024,256) \t95.4% \t\t0.65679% \t6.19765% \t0.82382\t\t0.82497\t\t0.03402\t\t0.92692\t\n",
      "(1024,1024) \t3.04% \t\t1.93852% \t2.19416% \t0.02452\t\t0.00216\t\t2e-05\t\t0.36324\t\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_4')\n",
    "model.predictMultiGPU(random=False, gpu=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict Original Diff \t\tPredict Original Diff \t\tPredict Original Diff\n",
      "---------------------------------------------------------------------------------------\n",
      "VALIDATION: 700\t\t67.73242%\t\t\t3.62656%\t\t\t74.49562%\t\n",
      "---------------------------------------------------------------------------------------\n",
      "TEST: 300\t\t69.07099%\t\t\t3.56130%\t\t\t73.37634%\t\n"
     ]
    }
   ],
   "source": [
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "-------------RelationGraph-------------\n",
      "Gene\t1024\n",
      "3\tann-(1024, 128), expr-(1024, 256), ppi-(1024, 1024)\n",
      "0\t\n",
      "GO term\t128\n",
      "0\t\n",
      "1\tann-(1024, 128)\n",
      "Experimental condition\t256\n",
      "0\t\n",
      "1\texpr-(1024, 256)\n",
      "\n",
      "ann\t(1024, 128)\n",
      "expr\t(1024, 256)\n",
      "ppi\t(1024, 1024)\n",
      "Data\t\tDensity\t\tPredict\t\tBaseLine\tAVG Mean\tPredict (mean)\tPredict (min)\tPredict (max)\t\n",
      "(1024,128) \t4.89% \t\t2.81498% \t5.76204% \t0.04888\t\t0.01626\t\t0.0\t\t0.90035\t\n",
      "(1024,256) \t95.4% \t\t0.6488% \t6.12769% \t0.82382\t\t0.82943\t\t0.02292\t\t0.93934\t\n",
      "(1024,1024) \t3.04% \t\t1.95117% \t2.17309% \t0.02452\t\t0.00184\t\t0.0\t\t0.34275\t\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_5')\n",
    "model.predictMultiGPU(random=False, gpu=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict Original Diff \t\tPredict Original Diff \t\tPredict Original Diff\n",
      "---------------------------------------------------------------------------------------\n",
      "VALIDATION: 700\t\t67.03018%\t\t\t3.49962%\t\t\t75.46737%\t\n",
      "---------------------------------------------------------------------------------------\n",
      "TEST: 300\t\t68.22036%\t\t\t3.44136%\t\t\t74.46256%\t\n"
     ]
    }
   ],
   "source": [
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "-------------RelationGraph-------------\n",
      "Gene\t1024\n",
      "3\tann-(1024, 128), expr-(1024, 256), ppi-(1024, 1024)\n",
      "0\t\n",
      "GO term\t128\n",
      "0\t\n",
      "1\tann-(1024, 128)\n",
      "Experimental condition\t256\n",
      "0\t\n",
      "1\texpr-(1024, 256)\n",
      "\n",
      "ann\t(1024, 128)\n",
      "expr\t(1024, 256)\n",
      "ppi\t(1024, 1024)\n",
      "Data\t\tDensity\t\tPredict\t\tBaseLine\tAVG Mean\tPredict (mean)\tPredict (min)\tPredict (max)\t\n",
      "(1024,128) \t4.89% \t\t2.7701% \t5.78326% \t0.04888\t\t0.01653\t\t0.0\t\t0.94021\t\n",
      "(1024,256) \t95.4% \t\t0.64234% \t6.11717% \t0.82382\t\t0.83069\t\t0.01585\t\t0.94659\t\n",
      "(1024,1024) \t3.04% \t\t1.95013% \t2.17093% \t0.02452\t\t0.00181\t\t0.0\t\t0.32187\t\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_6')\n",
    "model.predictMultiGPU(random=False, gpu=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict Original Diff \t\tPredict Original Diff \t\tPredict Original Diff\n",
      "---------------------------------------------------------------------------------------\n",
      "VALIDATION: 700\t\t66.98942%\t\t\t3.42090%\t\t\t75.56724%\t\n",
      "---------------------------------------------------------------------------------------\n",
      "TEST: 300\t\t68.17378%\t\t\t3.33237%\t\t\t74.52922%\t\n"
     ]
    }
   ],
   "source": [
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "-------------RelationGraph-------------\n",
      "Gene\t1024\n",
      "3\tann-(1024, 128), expr-(1024, 256), ppi-(1024, 1024)\n",
      "0\t\n",
      "GO term\t128\n",
      "0\t\n",
      "1\tann-(1024, 128)\n",
      "Experimental condition\t256\n",
      "0\t\n",
      "1\texpr-(1024, 256)\n",
      "\n",
      "ann\t(1024, 128)\n",
      "expr\t(1024, 256)\n",
      "ppi\t(1024, 1024)\n",
      "Data\t\tDensity\t\tPredict\t\tBaseLine\tAVG Mean\tPredict (mean)\tPredict (min)\tPredict (max)\t\n",
      "(1024,128) \t4.89% \t\t2.65205% \t5.86583% \t0.04888\t\t0.01771\t\t0.0\t\t0.96483\t\n",
      "(1024,256) \t95.4% \t\t0.59777% \t6.24296% \t0.82382\t\t0.82883\t\t0.00895\t\t0.95252\t\n",
      "(1024,1024) \t3.04% \t\t1.93719% \t2.1849% \t0.02452\t\t0.00203\t\t0.0\t\t0.31495\t\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_7')\n",
    "model.predictMultiGPU(random=False, gpu=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict Original Diff \t\tPredict Original Diff \t\tPredict Original Diff\n",
      "---------------------------------------------------------------------------------------\n",
      "VALIDATION: 700\t\t65.49415%\t\t\t3.39757%\t\t\t74.86562%\t\n",
      "---------------------------------------------------------------------------------------\n",
      "TEST: 300\t\t66.80605%\t\t\t3.28354%\t\t\t73.82349%\t\n"
     ]
    }
   ],
   "source": [
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "-------------RelationGraph-------------\n",
      "Gene\t1024\n",
      "3\tann-(1024, 128), expr-(1024, 256), ppi-(1024, 1024)\n",
      "0\t\n",
      "GO term\t128\n",
      "0\t\n",
      "1\tann-(1024, 128)\n",
      "Experimental condition\t256\n",
      "0\t\n",
      "1\texpr-(1024, 256)\n",
      "\n",
      "ann\t(1024, 128)\n",
      "expr\t(1024, 256)\n",
      "ppi\t(1024, 1024)\n",
      "Data\t\tDensity\t\tPredict\t\tBaseLine\tAVG Mean\tPredict (mean)\tPredict (min)\tPredict (max)\t\n",
      "(1024,128) \t4.89% \t\t2.5965% \t5.90219% \t0.04888\t\t0.01798\t\t0.0\t\t0.98814\t\n",
      "(1024,256) \t95.4% \t\t0.59658% \t6.27389% \t0.82382\t\t0.83206\t\t0.0071\t\t0.96184\t\n",
      "(1024,1024) \t3.04% \t\t1.94748% \t2.17438% \t0.02452\t\t0.00179\t\t0.0\t\t0.29769\t\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_8')\n",
    "model.predictMultiGPU(random=False, gpu=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict Original Diff \t\tPredict Original Diff \t\tPredict Original Diff\n",
      "---------------------------------------------------------------------------------------\n",
      "VALIDATION: 700\t\t66.11280%\t\t\t3.39241%\t\t\t75.62340%\t\n",
      "---------------------------------------------------------------------------------------\n",
      "TEST: 300\t\t67.03613%\t\t\t3.31031%\t\t\t74.55358%\t\n"
     ]
    }
   ],
   "source": [
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "-------------RelationGraph-------------\n",
      "Gene\t1024\n",
      "3\tann-(1024, 128), expr-(1024, 256), ppi-(1024, 1024)\n",
      "0\t\n",
      "GO term\t128\n",
      "0\t\n",
      "1\tann-(1024, 128)\n",
      "Experimental condition\t256\n",
      "0\t\n",
      "1\texpr-(1024, 256)\n",
      "\n",
      "ann\t(1024, 128)\n",
      "expr\t(1024, 256)\n",
      "ppi\t(1024, 1024)\n",
      "Data\t\tDensity\t\tPredict\t\tBaseLine\tAVG Mean\tPredict (mean)\tPredict (min)\tPredict (max)\t\n",
      "(1024,128) \t4.89% \t\t2.47557% \t6.06502% \t0.04888\t\t0.01954\t\t0.0\t\t0.99884\t\n",
      "(1024,256) \t95.4% \t\t0.57449% \t6.21994% \t0.82382\t\t0.83079\t\t0.00306\t\t0.96343\t\n",
      "(1024,1024) \t3.04% \t\t1.94466% \t2.17295% \t0.02452\t\t0.00183\t\t0.0\t\t0.2946\t\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_9')\n",
    "model.predictMultiGPU(random=False, gpu=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict Original Diff \t\tPredict Original Diff \t\tPredict Original Diff\n",
      "---------------------------------------------------------------------------------------\n",
      "VALIDATION: 700\t\t64.21195%\t\t\t3.13202%\t\t\t75.54541%\t\n",
      "---------------------------------------------------------------------------------------\n",
      "TEST: 300\t\t64.50717%\t\t\t3.16531%\t\t\t74.42326%\t\n"
     ]
    }
   ],
   "source": [
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "-------------RelationGraph-------------\n",
      "Gene\t1024\n",
      "3\tann-(1024, 128), expr-(1024, 256), ppi-(1024, 1024)\n",
      "0\t\n",
      "GO term\t128\n",
      "0\t\n",
      "1\tann-(1024, 128)\n",
      "Experimental condition\t256\n",
      "0\t\n",
      "1\texpr-(1024, 256)\n",
      "\n",
      "ann\t(1024, 128)\n",
      "expr\t(1024, 256)\n",
      "ppi\t(1024, 1024)\n",
      "Data\t\tDensity\t\tPredict\t\tBaseLine\tAVG Mean\tPredict (mean)\tPredict (min)\tPredict (max)\t\n",
      "(1024,128) \t4.89% \t\t2.34798% \t6.20083% \t0.04888\t\t0.02084\t\t0.0\t\t0.99966\t\n",
      "(1024,256) \t95.4% \t\t0.53947% \t6.29669% \t0.82382\t\t0.82572\t\t0.00078\t\t0.96858\t\n",
      "(1024,1024) \t3.04% \t\t1.92539% \t2.19243% \t0.02452\t\t0.00218\t\t0.0\t\t0.29972\t\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_10')\n",
    "model.predictMultiGPU(random=False, gpu=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict Original Diff \t\tPredict Original Diff \t\tPredict Original Diff\n",
      "---------------------------------------------------------------------------------------\n",
      "VALIDATION: 700\t\t63.69123%\t\t\t3.07177%\t\t\t74.46317%\t\n",
      "---------------------------------------------------------------------------------------\n",
      "TEST: 300\t\t63.77140%\t\t\t3.04399%\t\t\t73.31073%\t\n"
     ]
    }
   ],
   "source": [
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "-------------RelationGraph-------------\n",
      "Gene\t1024\n",
      "3\tann-(1024, 128), expr-(1024, 256), ppi-(1024, 1024)\n",
      "0\t\n",
      "GO term\t128\n",
      "0\t\n",
      "1\tann-(1024, 128)\n",
      "Experimental condition\t256\n",
      "0\t\n",
      "1\texpr-(1024, 256)\n",
      "\n",
      "ann\t(1024, 128)\n",
      "expr\t(1024, 256)\n",
      "ppi\t(1024, 1024)\n",
      "Data\t\tDensity\t\tPredict\t\tBaseLine\tAVG Mean\tPredict (mean)\tPredict (min)\tPredict (max)\t\n",
      "(1024,128) \t4.89% \t\t2.18516% \t6.21018% \t0.04888\t\t0.02193\t\t0.0\t\t0.99858\t\n",
      "(1024,256) \t95.4% \t\t0.54901% \t6.1957% \t0.82382\t\t0.82594\t\t0.00042\t\t0.96816\t\n",
      "(1024,1024) \t3.04% \t\t1.92783% \t2.18482% \t0.02452\t\t0.00205\t\t0.0\t\t0.29597\t\n",
      "\n",
      "Predict Original Diff \t\tPredict Original Diff \t\tPredict Original Diff\n",
      "---------------------------------------------------------------------------------------\n",
      "VALIDATION: 700\t\t64.30814%\t\t\t2.95552%\t\t\t74.93851%\t\n",
      "---------------------------------------------------------------------------------------\n",
      "TEST: 300\t\t64.80150%\t\t\t2.91757%\t\t\t73.70765%\t\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_11')\n",
    "model.predictMultiGPU(random=False, gpu=3)\n",
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "-------------RelationGraph-------------\n",
      "Gene\t1024\n",
      "3\tann-(1024, 128), expr-(1024, 256), ppi-(1024, 1024)\n",
      "0\t\n",
      "GO term\t128\n",
      "0\t\n",
      "1\tann-(1024, 128)\n",
      "Experimental condition\t256\n",
      "0\t\n",
      "1\texpr-(1024, 256)\n",
      "\n",
      "ann\t(1024, 128)\n",
      "expr\t(1024, 256)\n",
      "ppi\t(1024, 1024)\n",
      "Data\t\tDensity\t\tPredict\t\tBaseLine\tAVG Mean\tPredict (mean)\tPredict (min)\tPredict (max)\t\n",
      "(1024,128) \t4.89% \t\t1.94484% \t7.05823% \t0.04888\t\t0.02815\t\t0.0\t\t0.99992\t\n",
      "(1024,256) \t95.4% \t\t0.52312% \t6.31362% \t0.82382\t\t0.82687\t\t0.00011\t\t0.9751\t\n",
      "(1024,1024) \t3.04% \t\t1.92259% \t2.18931% \t0.02452\t\t0.0021\t\t0.0\t\t0.29607\t\n",
      "\n",
      "Predict Original Diff \t\tPredict Original Diff \t\tPredict Original Diff\n",
      "---------------------------------------------------------------------------------------\n",
      "VALIDATION: 700\t\t54.60915%\t\t\t2.97918%\t\t\t74.80998%\t\n",
      "---------------------------------------------------------------------------------------\n",
      "TEST: 300\t\t55.20529%\t\t\t3.00124%\t\t\t73.53529%\t\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_12')\n",
    "model.predictMultiGPU(random=False, gpu=3)\n",
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "-------------RelationGraph-------------\n",
      "Gene\t1024\n",
      "3\tann-(1024, 128), expr-(1024, 256), ppi-(1024, 1024)\n",
      "0\t\n",
      "GO term\t128\n",
      "0\t\n",
      "1\tann-(1024, 128)\n",
      "Experimental condition\t256\n",
      "0\t\n",
      "1\texpr-(1024, 256)\n",
      "\n",
      "ann\t(1024, 128)\n",
      "expr\t(1024, 256)\n",
      "ppi\t(1024, 1024)\n",
      "Data\t\tDensity\t\tPredict\t\tBaseLine\tAVG Mean\tPredict (mean)\tPredict (min)\tPredict (max)\t\n",
      "(1024,128) \t4.89% \t\t1.93802% \t6.48253% \t0.04888\t\t0.02452\t\t0.0\t\t0.99995\t\n",
      "(1024,256) \t95.4% \t\t0.51286% \t6.40558% \t0.82382\t\t0.82393\t\t4e-05\t\t0.97394\t\n",
      "(1024,1024) \t3.04% \t\t1.91213% \t2.20078% \t0.02452\t\t0.00231\t\t0.0\t\t0.33066\t\n",
      "\n",
      "Predict Original Diff \t\tPredict Original Diff \t\tPredict Original Diff\n",
      "---------------------------------------------------------------------------------------\n",
      "VALIDATION: 700\t\t64.39077%\t\t\t3.14237%\t\t\t74.19231%\t\n",
      "---------------------------------------------------------------------------------------\n",
      "TEST: 300\t\t65.22204%\t\t\t3.13006%\t\t\t72.88914%\t\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_13')\n",
    "model.predictMultiGPU(random=False, gpu=3)\n",
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "0.0\n",
      "1.0\n",
      "-------------RelationGraph-------------\n",
      "Gene\t1024\n",
      "3\tann-(1024, 128), expr-(1024, 256), ppi-(1024, 1024)\n",
      "0\t\n",
      "GO term\t128\n",
      "0\t\n",
      "1\tann-(1024, 128)\n",
      "Experimental condition\t256\n",
      "0\t\n",
      "1\texpr-(1024, 256)\n",
      "\n",
      "ann\t(1024, 128)\n",
      "expr\t(1024, 256)\n",
      "ppi\t(1024, 1024)\n",
      "Data\t\tDensity\t\tPredict\t\tBaseLine\tAVG Mean\tPredict (mean)\tPredict (min)\tPredict (max)\t\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1,128,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_21/conv2d_8/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model_21/conv2d_8/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, model_21/conv2d_8/Conv2D/ReadVariableOp)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node conv2d_22_16/concat/_18317}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2692_conv2d_22_16/concat\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6e918e976e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiModal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_test_cells\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumOfExperiment\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_14'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictMultiGPU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_hidden_cells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5cc03b07a2e6>\u001b[0m in \u001b[0;36mpredictMultiGPU\u001b[0;34m(self, random, gpu)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduplicateBatchData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduplicateBatchData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffled_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m       return training_arrays.predict_loop(\n\u001b[0;32m-> 1878\u001b[0;31m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, inputs, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,128,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_21/conv2d_8/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model_21/conv2d_8/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, model_21/conv2d_8/Conv2D/ReadVariableOp)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node conv2d_22_16/concat/_18317}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2692_conv2d_22_16/concat\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_14')\n",
    "model.predictMultiGPU(random=False, gpu=3)\n",
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_15')\n",
    "model.predictMultiGPU(random=False, gpu=3)\n",
    "model.predict_hidden_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "    \n",
    "numOfExperiment = 'model_weigth'\n",
    "graph1 = load_dicty('clustering', 2)\n",
    "\n",
    "model = MultiModal(graph=graph1, path=folder, load_test_cells=True)\n",
    "model.load_model(folder, str(numOfExperiment) + '_16')\n",
    "model.predictMultiGPU(random=False, gpu=3)\n",
    "model.predict_hidden_cells()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
