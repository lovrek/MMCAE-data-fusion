{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------RelationGraph-------------\n",
      "GO term\t116\n",
      "1\tann_T-(116, 1219)\n",
      "1\tann-(1219, 116)\n",
      "Experimental condition\t282\n",
      "1\texpr_T-(282, 1219)\n",
      "1\texpr-(1219, 282)\n",
      "Gene\t1219\n",
      "3\tann-(1219, 116), expr-(1219, 282), ppi-(1219, 1219)\n",
      "2\tann_T-(116, 1219), expr_T-(282, 1219)\n",
      "\n",
      "ann_T (116, 1219)\n",
      "ann (1219, 116)\n",
      "expr_T (282, 1219)\n",
      "expr (1219, 282)\n",
      "ppi (1219, 1219)\n",
      "GO term: 12\n",
      "Experimental condition: 28\n",
      "Gene: 122\n",
      "(162, 162)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [3.62695086, 5.36584517, 4.71983726, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [3.6707664 , 5.48442342, 4.73802135, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [3.66440744, 7.15474816, 6.39846681, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from relationGraph import Relation, RelationGraph, MatrixOfRelationGraph\n",
    "from base import load_source\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "from main import test_build_relation_graph_with_symertic_data, test_convert_graph_to_2D_matrix, test_get_matix_for_autoencoder\n",
    "\n",
    "graph = test_build_relation_graph_with_symertic_data()\n",
    "test_get_matix_for_autoencoder(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------RelationGraph-------------\n",
      "Experimental condition\t282\n",
      "1\texpr_T-(282, 1219)\n",
      "1\texpr-(1219, 282)\n",
      "GO term\t116\n",
      "1\tann_T-(116, 1219)\n",
      "1\tann-(1219, 116)\n",
      "Gene\t1219\n",
      "3\tann-(1219, 116), expr-(1219, 282), ppi-(1219, 1219)\n",
      "2\tann_T-(116, 1219), expr_T-(282, 1219)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph.display_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ann (1219, 116)\n",
      "expr (1219, 282)\n",
      "ppi (1219, 1219)\n",
      "ann_T (116, 1219)\n",
      "expr_T (282, 1219)\n",
      "Gene: 122\n",
      "GO term: 12\n",
      "Experimental condition: 28\n",
      "(162, 162)\n",
      "(26244,)\n"
     ]
    }
   ],
   "source": [
    "mrg = MatrixOfRelationGraph(graph=graph)\n",
    "mrg.convert_to_2D_matrix()\n",
    "data = mrg.density_data()\n",
    "print(data.shape)\n",
    "data = data.flatten()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26244,)\n",
      "[[5.00661389 4.83041553 4.8573831  ... 0.79615493 4.66824827 4.0636104 ]\n",
      " [5.00661389 4.83041553 4.8573831  ... 0.79615493 4.66824827 4.0636104 ]\n",
      " [5.00661389 4.83041553 4.8573831  ... 0.79615493 4.66824827 4.0636104 ]\n",
      " ...\n",
      " [5.00661389 4.83041553 4.8573831  ... 0.79615493 4.66824827 4.0636104 ]\n",
      " [5.00661389 4.83041553 4.8573831  ... 0.79615493 4.66824827 4.0636104 ]\n",
      " [5.00661389 4.83041553 4.8573831  ... 0.79615493 4.66824827 4.0636104 ]]\n",
      "26244\n",
      "Epoch 1/300\n",
      "1000/1000 [==============================] - 1s 873us/step - loss: 50.7841\n",
      "Epoch 2/300\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 50.7825\n",
      "Epoch 3/300\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 50.7810\n",
      "Epoch 4/300\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 50.7795\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - 1s 578us/step - loss: 50.7779\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 1s 530us/step - loss: 50.7764\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 50.7748\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 50.7733\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 0s 499us/step - loss: 50.7717\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 0s 451us/step - loss: 50.7702\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 0s 491us/step - loss: 50.7686\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 1s 574us/step - loss: 50.7671\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 1s 501us/step - loss: 50.7655\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 0s 469us/step - loss: 50.7640\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 0s 447us/step - loss: 50.7624\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 0s 499us/step - loss: 50.7609\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 50.7593\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 50.7578\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 1s 568us/step - loss: 50.7562\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 1s 610us/step - loss: 50.7547\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 1s 676us/step - loss: 50.7531\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 1s 694us/step - loss: 50.7516\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 1s 679us/step - loss: 50.7500\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 1s 637us/step - loss: 50.7485\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 1s 653us/step - loss: 50.7470\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 1s 613us/step - loss: 50.7454\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 1s 709us/step - loss: 50.7439\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 50.7423\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 1s 667us/step - loss: 50.7408\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 1s 650us/step - loss: 50.7392\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 50.7377\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 50.7361\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 50.7346\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 50.7330\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 50.7315\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 1s 712us/step - loss: 50.7299\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 1s 712us/step - loss: 50.7284\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 1s 647us/step - loss: 50.7268\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 50.7253\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 1s 642us/step - loss: 50.7238\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 50.7222\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 50.7207\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 50.7191\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 50.7176\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 50.7160\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 50.7145\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 1s 579us/step - loss: 50.7129\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 50.7114\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 50.7098\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 50.7083\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 1s 608us/step - loss: 50.7068\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 50.7052\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 1s 582us/step - loss: 50.7037\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 1s 624us/step - loss: 50.7021\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 1s 653us/step - loss: 50.7006\n",
      "Epoch 56/300\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 50.6990\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 0s 500us/step - loss: 50.6975\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 0s 497us/step - loss: 50.6959\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 1s 571us/step - loss: 50.6944\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 1s 707us/step - loss: 50.6928\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 50.6913\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 1s 611us/step - loss: 50.68970s\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 50.6882\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 1s 640us/step - loss: 50.6867\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 1s 641us/step - loss: 50.6851\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 1s 647us/step - loss: 50.6836\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 50.6820\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 50.6805\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 1s 697us/step - loss: 50.6789\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 50.6774\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 1s 635us/step - loss: 50.6758\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 50.6743\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 1s 625us/step - loss: 50.6728\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 50.6712\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 1s 502us/step - loss: 50.6697\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 50.6681\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 1s 621us/step - loss: 50.6666\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 50.6650\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 1s 669us/step - loss: 50.6635\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 1s 625us/step - loss: 50.6619\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 1s 654us/step - loss: 50.6604\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 50.6589\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 1s 673us/step - loss: 50.6573\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 1s 619us/step - loss: 50.6558\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 1s 624us/step - loss: 50.6542\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 1s 666us/step - loss: 50.6527\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 1s 704us/step - loss: 50.6511\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 1s 650us/step - loss: 50.6496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 1s 649us/step - loss: 50.6480\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 1s 679us/step - loss: 50.6465\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 50.6450\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 50.6434\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 1s 635us/step - loss: 50.6419\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 1s 696us/step - loss: 50.6403\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 50.6388\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 50.6372\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 50.6357\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 50.6342\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 50.6326\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 50.6311\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 50.6295\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 1s 628us/step - loss: 50.6280\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 50.6264\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 1s 706us/step - loss: 50.6249\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 1s 651us/step - loss: 50.6234\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 1s 714us/step - loss: 50.6218\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 1s 699us/step - loss: 50.6203\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 1s 692us/step - loss: 50.6187\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 1s 721us/step - loss: 50.6172\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 1s 733us/step - loss: 50.6156\n",
      "Epoch 111/300\n",
      "1000/1000 [==============================] - 1s 665us/step - loss: 50.6141\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 1s 672us/step - loss: 50.6125\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 1s 702us/step - loss: 50.6110\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 1s 669us/step - loss: 50.6095\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 1s 690us/step - loss: 50.6079\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 1s 645us/step - loss: 50.6064\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 50.6048\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 50.6033\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 50.6018\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 50.6002\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 50.5987\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 50.5971\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 50.5956\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 1s 631us/step - loss: 50.5940\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 1s 612us/step - loss: 50.5925\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 1s 628us/step - loss: 50.5910\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 1s 680us/step - loss: 50.5894\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 1s 635us/step - loss: 50.5879\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 1s 666us/step - loss: 50.5863\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 1s 697us/step - loss: 50.5848\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 1s 724us/step - loss: 50.5832\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 1s 715us/step - loss: 50.5817\n",
      "Epoch 133/300\n",
      "1000/1000 [==============================] - 1s 672us/step - loss: 50.5802\n",
      "Epoch 134/300\n",
      "1000/1000 [==============================] - 1s 684us/step - loss: 50.5786\n",
      "Epoch 135/300\n",
      "1000/1000 [==============================] - 1s 692us/step - loss: 50.5771\n",
      "Epoch 136/300\n",
      "1000/1000 [==============================] - 1s 633us/step - loss: 50.5755\n",
      "Epoch 137/300\n",
      "1000/1000 [==============================] - 1s 628us/step - loss: 50.5740\n",
      "Epoch 138/300\n",
      "1000/1000 [==============================] - 1s 733us/step - loss: 50.5725\n",
      "Epoch 139/300\n",
      "1000/1000 [==============================] - 1s 620us/step - loss: 50.5709\n",
      "Epoch 140/300\n",
      "1000/1000 [==============================] - 1s 692us/step - loss: 50.5694\n",
      "Epoch 141/300\n",
      "1000/1000 [==============================] - 1s 682us/step - loss: 50.5678\n",
      "Epoch 142/300\n",
      "1000/1000 [==============================] - 1s 690us/step - loss: 50.5663\n",
      "Epoch 143/300\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 50.5647\n",
      "Epoch 144/300\n",
      "1000/1000 [==============================] - 1s 621us/step - loss: 50.5632\n",
      "Epoch 145/300\n",
      "1000/1000 [==============================] - 0s 499us/step - loss: 50.5617\n",
      "Epoch 146/300\n",
      "1000/1000 [==============================] - 0s 486us/step - loss: 50.5601\n",
      "Epoch 147/300\n",
      "1000/1000 [==============================] - 0s 464us/step - loss: 50.5586\n",
      "Epoch 148/300\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 50.5570\n",
      "Epoch 149/300\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 50.5555\n",
      "Epoch 150/300\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 50.5540\n",
      "Epoch 151/300\n",
      "1000/1000 [==============================] - 0s 474us/step - loss: 50.5524\n",
      "Epoch 152/300\n",
      "1000/1000 [==============================] - 0s 449us/step - loss: 50.5509\n",
      "Epoch 153/300\n",
      "1000/1000 [==============================] - 0s 498us/step - loss: 50.5493\n",
      "Epoch 154/300\n",
      "1000/1000 [==============================] - 1s 666us/step - loss: 50.5478\n",
      "Epoch 155/300\n",
      "1000/1000 [==============================] - 1s 693us/step - loss: 50.5463\n",
      "Epoch 156/300\n",
      "1000/1000 [==============================] - 1s 679us/step - loss: 50.5447\n",
      "Epoch 157/300\n",
      "1000/1000 [==============================] - 1s 666us/step - loss: 50.54320s - l\n",
      "Epoch 158/300\n",
      "1000/1000 [==============================] - 1s 647us/step - loss: 50.5416\n",
      "Epoch 159/300\n",
      "1000/1000 [==============================] - 1s 573us/step - loss: 50.5401\n",
      "Epoch 160/300\n",
      "1000/1000 [==============================] - 1s 707us/step - loss: 50.5385\n",
      "Epoch 161/300\n",
      "1000/1000 [==============================] - 1s 649us/step - loss: 50.5370\n",
      "Epoch 162/300\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 50.5355\n",
      "Epoch 163/300\n",
      "1000/1000 [==============================] - 1s 615us/step - loss: 50.5339\n",
      "Epoch 164/300\n",
      "1000/1000 [==============================] - 1s 651us/step - loss: 50.5324\n",
      "Epoch 165/300\n",
      "1000/1000 [==============================] - 1s 697us/step - loss: 50.5308\n",
      "Epoch 166/300\n",
      "1000/1000 [==============================] - 1s 650us/step - loss: 50.5293\n",
      "Epoch 167/300\n",
      "1000/1000 [==============================] - 1s 678us/step - loss: 50.5278\n",
      "Epoch 168/300\n",
      "1000/1000 [==============================] - 1s 668us/step - loss: 50.5262\n",
      "Epoch 169/300\n",
      "1000/1000 [==============================] - 1s 703us/step - loss: 50.52470s - loss: 50.\n",
      "Epoch 170/300\n",
      "1000/1000 [==============================] - 1s 622us/step - loss: 50.5231\n",
      "Epoch 171/300\n",
      "1000/1000 [==============================] - 1s 652us/step - loss: 50.5216\n",
      "Epoch 172/300\n",
      "1000/1000 [==============================] - 1s 640us/step - loss: 50.5201\n",
      "Epoch 173/300\n",
      "1000/1000 [==============================] - 1s 726us/step - loss: 50.5185\n",
      "Epoch 174/300\n",
      "1000/1000 [==============================] - 1s 695us/step - loss: 50.5170\n",
      "Epoch 175/300\n",
      "1000/1000 [==============================] - 1s 632us/step - loss: 50.5154\n",
      "Epoch 176/300\n",
      "1000/1000 [==============================] - 1s 705us/step - loss: 50.5139\n",
      "Epoch 177/300\n",
      "1000/1000 [==============================] - 1s 737us/step - loss: 50.5124\n",
      "Epoch 178/300\n",
      "1000/1000 [==============================] - 1s 627us/step - loss: 50.5108\n",
      "Epoch 179/300\n",
      "1000/1000 [==============================] - 1s 576us/step - loss: 50.5093\n",
      "Epoch 180/300\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 50.5077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "1000/1000 [==============================] - 1s 609us/step - loss: 50.5062\n",
      "Epoch 182/300\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 50.5047\n",
      "Epoch 183/300\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 50.5031\n",
      "Epoch 184/300\n",
      "1000/1000 [==============================] - 1s 668us/step - loss: 50.5016\n",
      "Epoch 185/300\n",
      "1000/1000 [==============================] - 1s 711us/step - loss: 50.5000\n",
      "Epoch 186/300\n",
      "1000/1000 [==============================] - 1s 676us/step - loss: 50.4985\n",
      "Epoch 187/300\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 50.4970\n",
      "Epoch 188/300\n",
      "1000/1000 [==============================] - 1s 663us/step - loss: 50.4954\n",
      "Epoch 189/300\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 50.4939\n",
      "Epoch 190/300\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 50.4924\n",
      "Epoch 191/300\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 50.4908\n",
      "Epoch 192/300\n",
      "1000/1000 [==============================] - 1s 576us/step - loss: 50.4893\n",
      "Epoch 193/300\n",
      "1000/1000 [==============================] - 1s 646us/step - loss: 50.4877\n",
      "Epoch 194/300\n",
      "1000/1000 [==============================] - 1s 673us/step - loss: 50.4862\n",
      "Epoch 195/300\n",
      "1000/1000 [==============================] - 1s 689us/step - loss: 50.4847\n",
      "Epoch 196/300\n",
      "1000/1000 [==============================] - 1s 571us/step - loss: 50.4831\n",
      "Epoch 197/300\n",
      "1000/1000 [==============================] - 1s 616us/step - loss: 50.4816\n",
      "Epoch 198/300\n",
      "1000/1000 [==============================] - 1s 685us/step - loss: 50.4800\n",
      "Epoch 199/300\n",
      "1000/1000 [==============================] - 1s 675us/step - loss: 50.4785\n",
      "Epoch 200/300\n",
      "1000/1000 [==============================] - 1s 671us/step - loss: 50.4770\n",
      "Epoch 201/300\n",
      "1000/1000 [==============================] - 1s 640us/step - loss: 50.4754\n",
      "Epoch 202/300\n",
      "1000/1000 [==============================] - 1s 686us/step - loss: 50.4739\n",
      "Epoch 203/300\n",
      "1000/1000 [==============================] - 1s 616us/step - loss: 50.4723\n",
      "Epoch 204/300\n",
      "1000/1000 [==============================] - 1s 705us/step - loss: 50.4708\n",
      "Epoch 205/300\n",
      "1000/1000 [==============================] - 1s 734us/step - loss: 50.4693\n",
      "Epoch 206/300\n",
      "1000/1000 [==============================] - 1s 673us/step - loss: 50.4677\n",
      "Epoch 207/300\n",
      "1000/1000 [==============================] - 1s 609us/step - loss: 50.4662\n",
      "Epoch 208/300\n",
      "1000/1000 [==============================] - 1s 622us/step - loss: 50.4647\n",
      "Epoch 209/300\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 50.4631\n",
      "Epoch 210/300\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 50.4616\n",
      "Epoch 211/300\n",
      "1000/1000 [==============================] - 1s 571us/step - loss: 50.4600\n",
      "Epoch 212/300\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 50.4585\n",
      "Epoch 213/300\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 50.4570\n",
      "Epoch 214/300\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 50.4554\n",
      "Epoch 215/300\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 50.4539\n",
      "Epoch 216/300\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 50.4523\n",
      "Epoch 217/300\n",
      "1000/1000 [==============================] - 1s 688us/step - loss: 50.4508\n",
      "Epoch 218/300\n",
      "1000/1000 [==============================] - 1s 707us/step - loss: 50.4493\n",
      "Epoch 219/300\n",
      "1000/1000 [==============================] - 1s 718us/step - loss: 50.4477\n",
      "Epoch 220/300\n",
      "1000/1000 [==============================] - 1s 693us/step - loss: 50.4462\n",
      "Epoch 221/300\n",
      "1000/1000 [==============================] - 1s 698us/step - loss: 50.4447\n",
      "Epoch 222/300\n",
      "1000/1000 [==============================] - 1s 746us/step - loss: 50.4431\n",
      "Epoch 223/300\n",
      "1000/1000 [==============================] - 1s 682us/step - loss: 50.4416\n",
      "Epoch 224/300\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 50.4400\n",
      "Epoch 225/300\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 50.4385\n",
      "Epoch 226/300\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 50.4370\n",
      "Epoch 227/300\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 50.4354\n",
      "Epoch 228/300\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 50.4339\n",
      "Epoch 229/300\n",
      "1000/1000 [==============================] - 1s 633us/step - loss: 50.4324\n",
      "Epoch 230/300\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 50.4308\n",
      "Epoch 231/300\n",
      "1000/1000 [==============================] - 0s 469us/step - loss: 50.4293\n",
      "Epoch 232/300\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 50.4277\n",
      "Epoch 233/300\n",
      "1000/1000 [==============================] - 1s 576us/step - loss: 50.4262\n",
      "Epoch 234/300\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 50.4247\n",
      "Epoch 235/300\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 50.4231\n",
      "Epoch 236/300\n",
      "1000/1000 [==============================] - 1s 616us/step - loss: 50.4216\n",
      "Epoch 237/300\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 50.4201\n",
      "Epoch 238/300\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 50.4185\n",
      "Epoch 239/300\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 50.4170\n",
      "Epoch 240/300\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 50.4155\n",
      "Epoch 241/300\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 50.4139\n",
      "Epoch 242/300\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 50.4124\n",
      "Epoch 243/300\n",
      "1000/1000 [==============================] - 1s 614us/step - loss: 50.41080s - l\n",
      "Epoch 244/300\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 50.4093\n",
      "Epoch 245/300\n",
      "1000/1000 [==============================] - 1s 655us/step - loss: 50.40780s - loss: 50.\n",
      "Epoch 246/300\n",
      "1000/1000 [==============================] - 1s 650us/step - loss: 50.4062\n",
      "Epoch 247/300\n",
      "1000/1000 [==============================] - 1s 574us/step - loss: 50.4047\n",
      "Epoch 248/300\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 50.4032\n",
      "Epoch 249/300\n",
      "1000/1000 [==============================] - 0s 488us/step - loss: 50.4016\n",
      "Epoch 250/300\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 50.4001\n",
      "Epoch 251/300\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 50.3986\n",
      "Epoch 252/300\n",
      "1000/1000 [==============================] - 1s 634us/step - loss: 50.3970\n",
      "Epoch 253/300\n",
      "1000/1000 [==============================] - 1s 624us/step - loss: 50.3955\n",
      "Epoch 254/300\n",
      "1000/1000 [==============================] - 1s 759us/step - loss: 50.3939\n",
      "Epoch 255/300\n",
      "1000/1000 [==============================] - 1s 733us/step - loss: 50.3924\n",
      "Epoch 256/300\n",
      "1000/1000 [==============================] - 1s 719us/step - loss: 50.3909\n",
      "Epoch 257/300\n",
      "1000/1000 [==============================] - 1s 781us/step - loss: 50.3893\n",
      "Epoch 258/300\n",
      "1000/1000 [==============================] - 1s 658us/step - loss: 50.3878\n",
      "Epoch 259/300\n",
      "1000/1000 [==============================] - 1s 615us/step - loss: 50.3863\n",
      "Epoch 260/300\n",
      "1000/1000 [==============================] - 1s 651us/step - loss: 50.3847\n",
      "Epoch 261/300\n",
      "1000/1000 [==============================] - 1s 687us/step - loss: 50.3832\n",
      "Epoch 262/300\n",
      "1000/1000 [==============================] - 1s 671us/step - loss: 50.3817\n",
      "Epoch 263/300\n",
      "1000/1000 [==============================] - 1s 770us/step - loss: 50.3801\n",
      "Epoch 264/300\n",
      "1000/1000 [==============================] - 1s 615us/step - loss: 50.3786\n",
      "Epoch 265/300\n",
      "1000/1000 [==============================] - 1s 710us/step - loss: 50.3770\n",
      "Epoch 266/300\n",
      "1000/1000 [==============================] - 1s 736us/step - loss: 50.3755\n",
      "Epoch 267/300\n",
      "1000/1000 [==============================] - 1s 640us/step - loss: 50.3740\n",
      "Epoch 268/300\n",
      "1000/1000 [==============================] - 1s 651us/step - loss: 50.3724\n",
      "Epoch 269/300\n",
      "1000/1000 [==============================] - 1s 646us/step - loss: 50.3709\n",
      "Epoch 270/300\n",
      "1000/1000 [==============================] - 1s 673us/step - loss: 50.3694\n",
      "Epoch 271/300\n",
      "1000/1000 [==============================] - 1s 614us/step - loss: 50.3678\n",
      "Epoch 272/300\n",
      "1000/1000 [==============================] - 1s 653us/step - loss: 50.3663\n",
      "Epoch 273/300\n",
      "1000/1000 [==============================] - 1s 568us/step - loss: 50.3648\n",
      "Epoch 274/300\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 50.3632\n",
      "Epoch 275/300\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 50.3617\n",
      "Epoch 276/300\n",
      "1000/1000 [==============================] - 1s 663us/step - loss: 50.3602\n",
      "Epoch 277/300\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 50.3586\n",
      "Epoch 278/300\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 50.3571\n",
      "Epoch 279/300\n",
      "1000/1000 [==============================] - 1s 534us/step - loss: 50.3555\n",
      "Epoch 280/300\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 50.3540\n",
      "Epoch 281/300\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 50.3525\n",
      "Epoch 282/300\n",
      "1000/1000 [==============================] - 1s 699us/step - loss: 50.3509\n",
      "Epoch 283/300\n",
      "1000/1000 [==============================] - 1s 728us/step - loss: 50.3494\n",
      "Epoch 284/300\n",
      "1000/1000 [==============================] - 1s 704us/step - loss: 50.3479\n",
      "Epoch 285/300\n",
      "1000/1000 [==============================] - 1s 614us/step - loss: 50.3463\n",
      "Epoch 286/300\n",
      "1000/1000 [==============================] - 1s 726us/step - loss: 50.3448\n",
      "Epoch 287/300\n",
      "1000/1000 [==============================] - 1s 685us/step - loss: 50.3433\n",
      "Epoch 288/300\n",
      "1000/1000 [==============================] - 1s 684us/step - loss: 50.3417\n",
      "Epoch 289/300\n",
      "1000/1000 [==============================] - 1s 733us/step - loss: 50.3402\n",
      "Epoch 290/300\n",
      "1000/1000 [==============================] - 1s 649us/step - loss: 50.3387\n",
      "Epoch 291/300\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 50.3371\n",
      "Epoch 292/300\n",
      "1000/1000 [==============================] - 1s 684us/step - loss: 50.3356\n",
      "Epoch 293/300\n",
      "1000/1000 [==============================] - 1s 579us/step - loss: 50.3341\n",
      "Epoch 294/300\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 50.3325\n",
      "Epoch 295/300\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 50.3310\n",
      "Epoch 296/300\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 50.3295\n",
      "Epoch 297/300\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 50.3279\n",
      "Epoch 298/300\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 50.3264\n",
      "Epoch 299/300\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 50.3249\n",
      "Epoch 300/300\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 50.3233\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dropout, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow import set_random_seed\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def seedy(s):\n",
    "    np.random.seed(s)\n",
    "    set_random_seed(s)\n",
    "\n",
    "\n",
    "class AutoEncoder:\n",
    "\n",
    "    def __init__(self, encoding_dim=3, data=None):\n",
    "        self.encoding_dim = encoding_dim\n",
    "#         r = lambda: np.random.randint(1, 3)\n",
    "#         self.x = np.array([[r(), r(), r()] for _ in range(1000)])\n",
    "        self.x = np.array([data for _ in range(1000)])\n",
    "        self.x_dim = self.x.shape[1]\n",
    "        print(self.x)\n",
    "        print(self.x_dim)\n",
    "\n",
    "    def _encoder(self):\n",
    "        inputs = Input(shape=(self.x[0].shape))\n",
    "        encoded = Dense(self.encoding_dim, activation='relu')(inputs)\n",
    "        model = Model(inputs, encoded)\n",
    "        self.encoder = model\n",
    "        return model\n",
    "\n",
    "    def _decoder(self):\n",
    "        inputs = Input(shape=(self.encoding_dim,))\n",
    "        decoded = Dense(self.x_dim)(inputs)\n",
    "        model = Model(inputs, decoded)\n",
    "        self.decoder = model\n",
    "        return model\n",
    "\n",
    "    def encoder_decoder(self):\n",
    "        ec = self._encoder()\n",
    "        dc = self._decoder()\n",
    "\n",
    "        inputs = Input(shape=self.x[0].shape)\n",
    "        ec_out = ec(inputs)\n",
    "        dc_out = dc(ec_out)\n",
    "        model = Model(inputs, dc_out)\n",
    "\n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    def fit(self, batch_size=100, epochs=300):\n",
    "        self.model.compile(optimizer='sgd', loss='mse')\n",
    "        log_dir = '/mag/logs/'\n",
    "        callbacks = [TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_images=True)]\n",
    "\n",
    "        self.model.fit(self.x, self.x,\n",
    "                       epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       callbacks=callbacks\n",
    "                      )\n",
    "\n",
    "    def save(self):\n",
    "        if not os.path.exists(r'/mag/weigths'):\n",
    "            os.mkdir(r'/mag/weigths')\n",
    "\n",
    "        self.encoder.save(r'/mag/weigths/encoder_weigths.h5')\n",
    "        self.decoder.save(r'/mag/weigths/decoder_weigths.h5')\n",
    "        self.model.save(r'/mag/weigths/ae_weigths.h5')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    seedy(2)\n",
    "    print(data.shape)\n",
    "    ae = AutoEncoder(encoding_dim=2, data=data)\n",
    "    ae.encoder_decoder()\n",
    "    ae.fit(batch_size=50, epochs=300)\n",
    "#     ae.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------RelationGraph-------------\n",
      "Gene\t1219\n",
      "3\tann-(1219, 116), expr-(1219, 282), ppi-(1219, 1219)\n",
      "2\tann_T-(116, 1219), expr_T-(282, 1219)\n",
      "GO term\t116\n",
      "1\tann_T-(116, 1219)\n",
      "1\tann-(1219, 116)\n",
      "Experimental condition\t282\n",
      "1\texpr_T-(282, 1219)\n",
      "1\texpr-(1219, 282)\n",
      "\n",
      "ann (1219, 116)\n",
      "expr (1219, 282)\n",
      "ppi (1219, 1219)\n",
      "ann_T (116, 1219)\n",
      "expr_T (282, 1219)\n",
      "Gene: 122\n",
      "GO term: 12\n",
      "Experimental condition: 28\n",
      "[[5.00661389 4.83041553 4.8573831  ... 0.79615493 4.66824827 4.0636104 ]\n",
      " [5.00661389 4.83041553 4.8573831  ... 0.79615493 4.66824827 4.0636104 ]\n",
      " [5.00661389 4.83041553 4.8573831  ... 0.79615493 4.66824827 4.0636104 ]\n",
      " ...\n",
      " [5.00661389 4.83041553 4.8573831  ... 0.79615493 4.66824827 4.0636104 ]\n",
      " [5.00661389 4.83041553 4.8573831  ... 0.79615493 4.66824827 4.0636104 ]\n",
      " [5.00661389 4.83041553 4.8573831  ... 0.79615493 4.66824827 4.0636104 ]]\n",
      "26244\n",
      "Epoch 1/300\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 50.7874\n",
      "Epoch 2/300\n",
      "100/100 [==============================] - 0s 566us/step - loss: 50.7846\n",
      "Epoch 3/300\n",
      "100/100 [==============================] - 0s 438us/step - loss: 50.7845\n",
      "Epoch 4/300\n",
      "100/100 [==============================] - 0s 560us/step - loss: 50.7843\n",
      "Epoch 5/300\n",
      "100/100 [==============================] - 0s 586us/step - loss: 50.7842\n",
      "Epoch 6/300\n",
      "100/100 [==============================] - 0s 566us/step - loss: 50.7840\n",
      "Epoch 7/300\n",
      "100/100 [==============================] - 0s 548us/step - loss: 50.7839\n",
      "Epoch 8/300\n",
      "100/100 [==============================] - 0s 499us/step - loss: 50.7837\n",
      "Epoch 9/300\n",
      "100/100 [==============================] - 0s 387us/step - loss: 50.7836\n",
      "Epoch 10/300\n",
      "100/100 [==============================] - 0s 598us/step - loss: 50.7834\n",
      "Epoch 11/300\n",
      "100/100 [==============================] - 0s 659us/step - loss: 50.7832\n",
      "Epoch 12/300\n",
      "100/100 [==============================] - 0s 543us/step - loss: 50.7831\n",
      "Epoch 13/300\n",
      "100/100 [==============================] - 0s 554us/step - loss: 50.7829\n",
      "Epoch 14/300\n",
      "100/100 [==============================] - 0s 511us/step - loss: 50.7828\n",
      "Epoch 15/300\n",
      "100/100 [==============================] - 0s 462us/step - loss: 50.7826\n",
      "Epoch 16/300\n",
      "100/100 [==============================] - 0s 457us/step - loss: 50.7825\n",
      "Epoch 17/300\n",
      "100/100 [==============================] - 0s 460us/step - loss: 50.7823\n",
      "Epoch 18/300\n",
      "100/100 [==============================] - 0s 461us/step - loss: 50.7822\n",
      "Epoch 19/300\n",
      "100/100 [==============================] - 0s 519us/step - loss: 50.7820\n",
      "Epoch 20/300\n",
      "100/100 [==============================] - 0s 522us/step - loss: 50.7818\n",
      "Epoch 21/300\n",
      "100/100 [==============================] - 0s 431us/step - loss: 50.7817\n",
      "Epoch 22/300\n",
      "100/100 [==============================] - 0s 548us/step - loss: 50.7815\n",
      "Epoch 23/300\n",
      "100/100 [==============================] - 0s 699us/step - loss: 50.7814\n",
      "Epoch 24/300\n",
      "100/100 [==============================] - 0s 597us/step - loss: 50.7812\n",
      "Epoch 25/300\n",
      "100/100 [==============================] - 0s 569us/step - loss: 50.7811\n",
      "Epoch 26/300\n",
      "100/100 [==============================] - 0s 538us/step - loss: 50.7809\n",
      "Epoch 27/300\n",
      "100/100 [==============================] - 0s 532us/step - loss: 50.7808\n",
      "Epoch 28/300\n",
      "100/100 [==============================] - 0s 763us/step - loss: 50.7806\n",
      "Epoch 29/300\n",
      "100/100 [==============================] - 0s 519us/step - loss: 50.7805\n",
      "Epoch 30/300\n",
      "100/100 [==============================] - 0s 516us/step - loss: 50.7803\n",
      "Epoch 31/300\n",
      "100/100 [==============================] - 0s 757us/step - loss: 50.7801\n",
      "Epoch 32/300\n",
      "100/100 [==============================] - 0s 543us/step - loss: 50.7800\n",
      "Epoch 33/300\n",
      "100/100 [==============================] - 0s 693us/step - loss: 50.7798\n",
      "Epoch 34/300\n",
      "100/100 [==============================] - 0s 561us/step - loss: 50.7797\n",
      "Epoch 35/300\n",
      "100/100 [==============================] - 0s 558us/step - loss: 50.7795\n",
      "Epoch 36/300\n",
      "100/100 [==============================] - 0s 519us/step - loss: 50.7794\n",
      "Epoch 37/300\n",
      "100/100 [==============================] - 0s 494us/step - loss: 50.7792\n",
      "Epoch 38/300\n",
      "100/100 [==============================] - 0s 462us/step - loss: 50.7791\n",
      "Epoch 39/300\n",
      "100/100 [==============================] - 0s 449us/step - loss: 50.7789\n",
      "Epoch 40/300\n",
      "100/100 [==============================] - 0s 511us/step - loss: 50.7787\n",
      "Epoch 41/300\n",
      "100/100 [==============================] - 0s 428us/step - loss: 50.7786\n",
      "Epoch 42/300\n",
      "100/100 [==============================] - 0s 429us/step - loss: 50.7784\n",
      "Epoch 43/300\n",
      "100/100 [==============================] - 0s 526us/step - loss: 50.7783\n",
      "Epoch 44/300\n",
      "100/100 [==============================] - 0s 462us/step - loss: 50.7781\n",
      "Epoch 45/300\n",
      "100/100 [==============================] - 0s 463us/step - loss: 50.7780\n",
      "Epoch 46/300\n",
      "100/100 [==============================] - 0s 460us/step - loss: 50.7778\n",
      "Epoch 47/300\n",
      "100/100 [==============================] - 0s 649us/step - loss: 50.7777\n",
      "Epoch 48/300\n",
      "100/100 [==============================] - 0s 449us/step - loss: 50.7775\n",
      "Epoch 49/300\n",
      "100/100 [==============================] - 0s 483us/step - loss: 50.7774\n",
      "Epoch 50/300\n",
      "100/100 [==============================] - 0s 561us/step - loss: 50.7772\n",
      "Epoch 51/300\n",
      "100/100 [==============================] - 0s 519us/step - loss: 50.7771\n",
      "Epoch 52/300\n",
      "100/100 [==============================] - 0s 493us/step - loss: 50.7769\n",
      "Epoch 53/300\n",
      "100/100 [==============================] - 0s 408us/step - loss: 50.7767\n",
      "Epoch 54/300\n",
      "100/100 [==============================] - 0s 491us/step - loss: 50.7766\n",
      "Epoch 55/300\n",
      "100/100 [==============================] - 0s 661us/step - loss: 50.7764\n",
      "Epoch 56/300\n",
      "100/100 [==============================] - 0s 583us/step - loss: 50.7763\n",
      "Epoch 57/300\n",
      "100/100 [==============================] - 0s 589us/step - loss: 50.7761\n",
      "Epoch 58/300\n",
      "100/100 [==============================] - 0s 513us/step - loss: 50.7760\n",
      "Epoch 59/300\n",
      "100/100 [==============================] - 0s 489us/step - loss: 50.7758\n",
      "Epoch 60/300\n",
      "100/100 [==============================] - 0s 442us/step - loss: 50.7757\n",
      "Epoch 61/300\n",
      "100/100 [==============================] - 0s 506us/step - loss: 50.7755\n",
      "Epoch 62/300\n",
      "100/100 [==============================] - 0s 511us/step - loss: 50.7753\n",
      "Epoch 63/300\n",
      "100/100 [==============================] - 0s 623us/step - loss: 50.7752\n",
      "Epoch 64/300\n",
      "100/100 [==============================] - 0s 512us/step - loss: 50.7750\n",
      "Epoch 65/300\n",
      "100/100 [==============================] - 0s 528us/step - loss: 50.7749\n",
      "Epoch 66/300\n",
      "100/100 [==============================] - 0s 471us/step - loss: 50.7747\n",
      "Epoch 67/300\n",
      "100/100 [==============================] - 0s 458us/step - loss: 50.7746\n",
      "Epoch 68/300\n",
      "100/100 [==============================] - 0s 558us/step - loss: 50.7744\n",
      "Epoch 69/300\n",
      "100/100 [==============================] - 0s 497us/step - loss: 50.7743\n",
      "Epoch 70/300\n",
      "100/100 [==============================] - 0s 505us/step - loss: 50.7741\n",
      "Epoch 71/300\n",
      "100/100 [==============================] - 0s 449us/step - loss: 50.7740\n",
      "Epoch 72/300\n",
      "100/100 [==============================] - 0s 460us/step - loss: 50.7738\n",
      "Epoch 73/300\n",
      "100/100 [==============================] - 0s 529us/step - loss: 50.7736\n",
      "Epoch 74/300\n",
      "100/100 [==============================] - 0s 555us/step - loss: 50.7735\n",
      "Epoch 75/300\n",
      "100/100 [==============================] - 0s 658us/step - loss: 50.7733\n",
      "Epoch 76/300\n",
      "100/100 [==============================] - 0s 609us/step - loss: 50.7732\n",
      "Epoch 77/300\n",
      "100/100 [==============================] - 0s 604us/step - loss: 50.7730\n",
      "Epoch 78/300\n",
      "100/100 [==============================] - 0s 669us/step - loss: 50.7729\n",
      "Epoch 79/300\n",
      "100/100 [==============================] - 0s 585us/step - loss: 50.7727\n",
      "Epoch 80/300\n",
      "100/100 [==============================] - 0s 701us/step - loss: 50.7726\n",
      "Epoch 81/300\n",
      "100/100 [==============================] - 0s 507us/step - loss: 50.7724\n",
      "Epoch 82/300\n",
      "100/100 [==============================] - 0s 580us/step - loss: 50.7723\n",
      "Epoch 83/300\n",
      "100/100 [==============================] - 0s 572us/step - loss: 50.7721\n",
      "Epoch 84/300\n",
      "100/100 [==============================] - 0s 608us/step - loss: 50.7719\n",
      "Epoch 85/300\n",
      "100/100 [==============================] - 0s 728us/step - loss: 50.7718\n",
      "Epoch 86/300\n",
      "100/100 [==============================] - 0s 598us/step - loss: 50.7716\n",
      "Epoch 87/300\n",
      "100/100 [==============================] - 0s 585us/step - loss: 50.7715\n",
      "Epoch 88/300\n",
      "100/100 [==============================] - 0s 576us/step - loss: 50.7713\n",
      "Epoch 89/300\n",
      "100/100 [==============================] - 0s 734us/step - loss: 50.7712\n",
      "Epoch 90/300\n",
      "100/100 [==============================] - 0s 566us/step - loss: 50.7710\n",
      "Epoch 91/300\n",
      "100/100 [==============================] - 0s 447us/step - loss: 50.7709\n",
      "Epoch 92/300\n",
      "100/100 [==============================] - 0s 558us/step - loss: 50.7707\n",
      "Epoch 93/300\n",
      "100/100 [==============================] - 0s 464us/step - loss: 50.7705\n",
      "Epoch 94/300\n",
      "100/100 [==============================] - 0s 383us/step - loss: 50.7704\n",
      "Epoch 95/300\n",
      "100/100 [==============================] - 0s 637us/step - loss: 50.7702\n",
      "Epoch 96/300\n",
      "100/100 [==============================] - 0s 443us/step - loss: 50.7701\n",
      "Epoch 97/300\n",
      "100/100 [==============================] - 0s 436us/step - loss: 50.7699\n",
      "Epoch 98/300\n",
      "100/100 [==============================] - 0s 550us/step - loss: 50.7698\n",
      "Epoch 99/300\n",
      "100/100 [==============================] - 0s 467us/step - loss: 50.7696\n",
      "Epoch 100/300\n",
      "100/100 [==============================] - 0s 511us/step - loss: 50.7695\n",
      "Epoch 101/300\n",
      "100/100 [==============================] - 0s 511us/step - loss: 50.7693\n",
      "Epoch 102/300\n",
      "100/100 [==============================] - 0s 477us/step - loss: 50.7692\n",
      "Epoch 103/300\n",
      "100/100 [==============================] - 0s 444us/step - loss: 50.7690\n",
      "Epoch 104/300\n",
      "100/100 [==============================] - 0s 404us/step - loss: 50.7689\n",
      "Epoch 105/300\n",
      "100/100 [==============================] - 0s 506us/step - loss: 50.7687\n",
      "Epoch 106/300\n",
      "100/100 [==============================] - 0s 537us/step - loss: 50.7685\n",
      "Epoch 107/300\n",
      "100/100 [==============================] - 0s 596us/step - loss: 50.7684\n",
      "Epoch 108/300\n",
      "100/100 [==============================] - 0s 498us/step - loss: 50.7682\n",
      "Epoch 109/300\n",
      "100/100 [==============================] - 0s 645us/step - loss: 50.7681\n",
      "Epoch 110/300\n",
      "100/100 [==============================] - 0s 677us/step - loss: 50.7679\n",
      "Epoch 111/300\n",
      "100/100 [==============================] - 0s 649us/step - loss: 50.7678\n",
      "Epoch 112/300\n",
      "100/100 [==============================] - 0s 745us/step - loss: 50.7676\n",
      "Epoch 113/300\n",
      "100/100 [==============================] - 0s 642us/step - loss: 50.7675\n",
      "Epoch 114/300\n",
      "100/100 [==============================] - 0s 713us/step - loss: 50.7673\n",
      "Epoch 115/300\n",
      "100/100 [==============================] - 0s 698us/step - loss: 50.7671\n",
      "Epoch 116/300\n",
      "100/100 [==============================] - 0s 618us/step - loss: 50.7670\n",
      "Epoch 117/300\n",
      "100/100 [==============================] - 0s 628us/step - loss: 50.7668\n",
      "Epoch 118/300\n",
      "100/100 [==============================] - 0s 650us/step - loss: 50.7667\n",
      "Epoch 119/300\n",
      "100/100 [==============================] - 0s 614us/step - loss: 50.7665\n",
      "Epoch 120/300\n",
      "100/100 [==============================] - 0s 730us/step - loss: 50.7664\n",
      "Epoch 121/300\n",
      "100/100 [==============================] - 0s 672us/step - loss: 50.7662\n",
      "Epoch 122/300\n",
      "100/100 [==============================] - 0s 641us/step - loss: 50.7661\n",
      "Epoch 123/300\n",
      "100/100 [==============================] - 0s 645us/step - loss: 50.7659\n",
      "Epoch 124/300\n",
      "100/100 [==============================] - 0s 734us/step - loss: 50.7658\n",
      "Epoch 125/300\n",
      "100/100 [==============================] - 0s 607us/step - loss: 50.7656\n",
      "Epoch 126/300\n",
      "100/100 [==============================] - 0s 704us/step - loss: 50.7654\n",
      "Epoch 127/300\n",
      "100/100 [==============================] - 0s 496us/step - loss: 50.7653\n",
      "Epoch 128/300\n",
      "100/100 [==============================] - 0s 516us/step - loss: 50.7651\n",
      "Epoch 129/300\n",
      "100/100 [==============================] - 0s 570us/step - loss: 50.7650\n",
      "Epoch 130/300\n",
      "100/100 [==============================] - 0s 513us/step - loss: 50.7648\n",
      "Epoch 131/300\n",
      "100/100 [==============================] - 0s 713us/step - loss: 50.7647\n",
      "Epoch 132/300\n",
      "100/100 [==============================] - 0s 700us/step - loss: 50.7645\n",
      "Epoch 133/300\n",
      "100/100 [==============================] - 0s 638us/step - loss: 50.7644\n",
      "Epoch 134/300\n",
      "100/100 [==============================] - 0s 633us/step - loss: 50.7642\n",
      "Epoch 135/300\n",
      "100/100 [==============================] - 0s 696us/step - loss: 50.7641\n",
      "Epoch 136/300\n",
      "100/100 [==============================] - 0s 496us/step - loss: 50.7639\n",
      "Epoch 137/300\n",
      "100/100 [==============================] - 0s 631us/step - loss: 50.7637\n",
      "Epoch 138/300\n",
      "100/100 [==============================] - 0s 669us/step - loss: 50.7636\n",
      "Epoch 139/300\n",
      "100/100 [==============================] - 0s 704us/step - loss: 50.7634\n",
      "Epoch 140/300\n",
      "100/100 [==============================] - 0s 685us/step - loss: 50.7633\n",
      "Epoch 141/300\n",
      "100/100 [==============================] - 0s 559us/step - loss: 50.7631\n",
      "Epoch 142/300\n",
      "100/100 [==============================] - 0s 563us/step - loss: 50.7630\n",
      "Epoch 143/300\n",
      "100/100 [==============================] - 0s 564us/step - loss: 50.7628\n",
      "Epoch 144/300\n",
      "100/100 [==============================] - 0s 531us/step - loss: 50.7627\n",
      "Epoch 145/300\n",
      "100/100 [==============================] - 0s 697us/step - loss: 50.7625\n",
      "Epoch 146/300\n",
      "100/100 [==============================] - 0s 609us/step - loss: 50.7624\n",
      "Epoch 147/300\n",
      "100/100 [==============================] - 0s 644us/step - loss: 50.7622\n",
      "Epoch 148/300\n",
      "100/100 [==============================] - 0s 524us/step - loss: 50.7620\n",
      "Epoch 149/300\n",
      "100/100 [==============================] - 0s 719us/step - loss: 50.7619\n",
      "Epoch 150/300\n",
      "100/100 [==============================] - 0s 443us/step - loss: 50.7617\n",
      "Epoch 151/300\n",
      "100/100 [==============================] - 0s 458us/step - loss: 50.7616\n",
      "Epoch 152/300\n",
      "100/100 [==============================] - 0s 472us/step - loss: 50.7614\n",
      "Epoch 153/300\n",
      "100/100 [==============================] - 0s 439us/step - loss: 50.7613\n",
      "Epoch 154/300\n",
      "100/100 [==============================] - 0s 436us/step - loss: 50.7611\n",
      "Epoch 155/300\n",
      "100/100 [==============================] - 0s 456us/step - loss: 50.7610\n",
      "Epoch 156/300\n",
      "100/100 [==============================] - 0s 472us/step - loss: 50.7608\n",
      "Epoch 157/300\n",
      "100/100 [==============================] - 0s 629us/step - loss: 50.7607\n",
      "Epoch 158/300\n",
      "100/100 [==============================] - 0s 481us/step - loss: 50.7605\n",
      "Epoch 159/300\n",
      "100/100 [==============================] - 0s 537us/step - loss: 50.7603\n",
      "Epoch 160/300\n",
      "100/100 [==============================] - 0s 388us/step - loss: 50.7602\n",
      "Epoch 161/300\n",
      "100/100 [==============================] - 0s 490us/step - loss: 50.7600\n",
      "Epoch 162/300\n",
      "100/100 [==============================] - 0s 505us/step - loss: 50.7599\n",
      "Epoch 163/300\n",
      "100/100 [==============================] - 0s 473us/step - loss: 50.7597\n",
      "Epoch 164/300\n",
      "100/100 [==============================] - 0s 477us/step - loss: 50.7596\n",
      "Epoch 165/300\n",
      "100/100 [==============================] - 0s 460us/step - loss: 50.7594\n",
      "Epoch 166/300\n",
      "100/100 [==============================] - 0s 488us/step - loss: 50.7593\n",
      "Epoch 167/300\n",
      "100/100 [==============================] - 0s 567us/step - loss: 50.7591\n",
      "Epoch 168/300\n",
      "100/100 [==============================] - 0s 535us/step - loss: 50.7589\n",
      "Epoch 169/300\n",
      "100/100 [==============================] - 0s 543us/step - loss: 50.7588\n",
      "Epoch 170/300\n",
      "100/100 [==============================] - 0s 421us/step - loss: 50.7586\n",
      "Epoch 171/300\n",
      "100/100 [==============================] - 0s 457us/step - loss: 50.7585\n",
      "Epoch 172/300\n",
      "100/100 [==============================] - 0s 513us/step - loss: 50.7583\n",
      "Epoch 173/300\n",
      "100/100 [==============================] - 0s 560us/step - loss: 50.7582\n",
      "Epoch 174/300\n",
      "100/100 [==============================] - 0s 585us/step - loss: 50.7580\n",
      "Epoch 175/300\n",
      "100/100 [==============================] - 0s 692us/step - loss: 50.7579\n",
      "Epoch 176/300\n",
      "100/100 [==============================] - 0s 594us/step - loss: 50.7577\n",
      "Epoch 177/300\n",
      "100/100 [==============================] - 0s 645us/step - loss: 50.7576\n",
      "Epoch 178/300\n",
      "100/100 [==============================] - 0s 748us/step - loss: 50.7574\n",
      "Epoch 179/300\n",
      "100/100 [==============================] - 0s 665us/step - loss: 50.7572\n",
      "Epoch 180/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 636us/step - loss: 50.7571\n",
      "Epoch 181/300\n",
      "100/100 [==============================] - 0s 616us/step - loss: 50.7569\n",
      "Epoch 182/300\n",
      "100/100 [==============================] - 0s 540us/step - loss: 50.7568\n",
      "Epoch 183/300\n",
      "100/100 [==============================] - 0s 659us/step - loss: 50.7566\n",
      "Epoch 184/300\n",
      "100/100 [==============================] - 0s 554us/step - loss: 50.7565\n",
      "Epoch 185/300\n",
      "100/100 [==============================] - 0s 623us/step - loss: 50.7563\n",
      "Epoch 186/300\n",
      "100/100 [==============================] - 0s 674us/step - loss: 50.7562\n",
      "Epoch 187/300\n",
      "100/100 [==============================] - 0s 794us/step - loss: 50.7560\n",
      "Epoch 188/300\n",
      "100/100 [==============================] - 0s 766us/step - loss: 50.7558\n",
      "Epoch 189/300\n",
      "100/100 [==============================] - 0s 679us/step - loss: 50.7557\n",
      "Epoch 190/300\n",
      "100/100 [==============================] - 0s 772us/step - loss: 50.7555\n",
      "Epoch 191/300\n",
      "100/100 [==============================] - 0s 673us/step - loss: 50.7554\n",
      "Epoch 192/300\n",
      "100/100 [==============================] - 0s 623us/step - loss: 50.7552\n",
      "Epoch 193/300\n",
      "100/100 [==============================] - 0s 610us/step - loss: 50.7551\n",
      "Epoch 194/300\n",
      "100/100 [==============================] - 0s 650us/step - loss: 50.7549\n",
      "Epoch 195/300\n",
      "100/100 [==============================] - 0s 764us/step - loss: 50.7548\n",
      "Epoch 196/300\n",
      "100/100 [==============================] - 0s 672us/step - loss: 50.7546\n",
      "Epoch 197/300\n",
      "100/100 [==============================] - 0s 509us/step - loss: 50.7545\n",
      "Epoch 198/300\n",
      "100/100 [==============================] - 0s 458us/step - loss: 50.7543\n",
      "Epoch 199/300\n",
      "100/100 [==============================] - 0s 548us/step - loss: 50.7542\n",
      "Epoch 200/300\n",
      "100/100 [==============================] - 0s 679us/step - loss: 50.7540\n",
      "Epoch 201/300\n",
      "100/100 [==============================] - 0s 532us/step - loss: 50.7538\n",
      "Epoch 202/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 50.75 - 0s 688us/step - loss: 50.7537\n",
      "Epoch 203/300\n",
      "100/100 [==============================] - 0s 624us/step - loss: 50.7535\n",
      "Epoch 204/300\n",
      "100/100 [==============================] - 0s 606us/step - loss: 50.7534\n",
      "Epoch 205/300\n",
      "100/100 [==============================] - 0s 506us/step - loss: 50.7532\n",
      "Epoch 206/300\n",
      "100/100 [==============================] - 0s 758us/step - loss: 50.7531\n",
      "Epoch 207/300\n",
      "100/100 [==============================] - 0s 665us/step - loss: 50.7529\n",
      "Epoch 208/300\n",
      "100/100 [==============================] - 0s 610us/step - loss: 50.7528\n",
      "Epoch 209/300\n",
      "100/100 [==============================] - 0s 577us/step - loss: 50.7526\n",
      "Epoch 210/300\n",
      "100/100 [==============================] - 0s 598us/step - loss: 50.7525\n",
      "Epoch 211/300\n",
      "100/100 [==============================] - 0s 512us/step - loss: 50.7523\n",
      "Epoch 212/300\n",
      "100/100 [==============================] - 0s 578us/step - loss: 50.7521\n",
      "Epoch 213/300\n",
      "100/100 [==============================] - 0s 485us/step - loss: 50.7520\n",
      "Epoch 214/300\n",
      "100/100 [==============================] - 0s 588us/step - loss: 50.7518\n",
      "Epoch 215/300\n",
      "100/100 [==============================] - 0s 830us/step - loss: 50.7517\n",
      "Epoch 216/300\n",
      "100/100 [==============================] - 0s 613us/step - loss: 50.7515\n",
      "Epoch 217/300\n",
      "100/100 [==============================] - 0s 551us/step - loss: 50.7514\n",
      "Epoch 218/300\n",
      "100/100 [==============================] - 0s 544us/step - loss: 50.7512\n",
      "Epoch 219/300\n",
      "100/100 [==============================] - 0s 666us/step - loss: 50.7510\n",
      "Epoch 220/300\n",
      "100/100 [==============================] - 0s 613us/step - loss: 50.7509\n",
      "Epoch 221/300\n",
      "100/100 [==============================] - 0s 574us/step - loss: 50.7507\n",
      "Epoch 222/300\n",
      "100/100 [==============================] - 0s 804us/step - loss: 50.7506\n",
      "Epoch 223/300\n",
      "100/100 [==============================] - 0s 570us/step - loss: 50.7504\n",
      "Epoch 224/300\n",
      "100/100 [==============================] - 0s 540us/step - loss: 50.7503\n",
      "Epoch 225/300\n",
      "100/100 [==============================] - 0s 543us/step - loss: 50.7501\n",
      "Epoch 226/300\n",
      "100/100 [==============================] - 0s 631us/step - loss: 50.7500\n",
      "Epoch 227/300\n",
      "100/100 [==============================] - 0s 541us/step - loss: 50.7498\n",
      "Epoch 228/300\n",
      "100/100 [==============================] - 0s 564us/step - loss: 50.7497\n",
      "Epoch 229/300\n",
      "100/100 [==============================] - 0s 577us/step - loss: 50.7495\n",
      "Epoch 230/300\n",
      "100/100 [==============================] - 0s 715us/step - loss: 50.7493\n",
      "Epoch 231/300\n",
      "100/100 [==============================] - 0s 588us/step - loss: 50.7492\n",
      "Epoch 232/300\n",
      "100/100 [==============================] - 0s 604us/step - loss: 50.7490\n",
      "Epoch 233/300\n",
      "100/100 [==============================] - 0s 510us/step - loss: 50.7489\n",
      "Epoch 234/300\n",
      "100/100 [==============================] - 0s 496us/step - loss: 50.7487\n",
      "Epoch 235/300\n",
      "100/100 [==============================] - 0s 492us/step - loss: 50.7486\n",
      "Epoch 236/300\n",
      "100/100 [==============================] - 0s 513us/step - loss: 50.7484\n",
      "Epoch 237/300\n",
      "100/100 [==============================] - 0s 652us/step - loss: 50.7483\n",
      "Epoch 238/300\n",
      "100/100 [==============================] - 0s 555us/step - loss: 50.7481\n",
      "Epoch 239/300\n",
      "100/100 [==============================] - 0s 659us/step - loss: 50.7480\n",
      "Epoch 240/300\n",
      "100/100 [==============================] - 0s 495us/step - loss: 50.7478\n",
      "Epoch 241/300\n",
      "100/100 [==============================] - 0s 545us/step - loss: 50.7476\n",
      "Epoch 242/300\n",
      "100/100 [==============================] - 0s 553us/step - loss: 50.7475\n",
      "Epoch 243/300\n",
      "100/100 [==============================] - 0s 653us/step - loss: 50.7473\n",
      "Epoch 244/300\n",
      "100/100 [==============================] - 0s 594us/step - loss: 50.7472\n",
      "Epoch 245/300\n",
      "100/100 [==============================] - 0s 641us/step - loss: 50.7470\n",
      "Epoch 246/300\n",
      "100/100 [==============================] - 0s 517us/step - loss: 50.7469\n",
      "Epoch 247/300\n",
      "100/100 [==============================] - 0s 489us/step - loss: 50.7467\n",
      "Epoch 248/300\n",
      "100/100 [==============================] - 0s 535us/step - loss: 50.7466\n",
      "Epoch 249/300\n",
      "100/100 [==============================] - 0s 539us/step - loss: 50.7464\n",
      "Epoch 250/300\n",
      "100/100 [==============================] - 0s 560us/step - loss: 50.7463\n",
      "Epoch 251/300\n",
      "100/100 [==============================] - 0s 548us/step - loss: 50.7461\n",
      "Epoch 252/300\n",
      "100/100 [==============================] - 0s 532us/step - loss: 50.7460\n",
      "Epoch 253/300\n",
      "100/100 [==============================] - 0s 522us/step - loss: 50.7458\n",
      "Epoch 254/300\n",
      "100/100 [==============================] - 0s 534us/step - loss: 50.7456\n",
      "Epoch 255/300\n",
      "100/100 [==============================] - 0s 517us/step - loss: 50.7455\n",
      "Epoch 256/300\n",
      "100/100 [==============================] - 0s 499us/step - loss: 50.7453\n",
      "Epoch 257/300\n",
      "100/100 [==============================] - 0s 570us/step - loss: 50.7452\n",
      "Epoch 258/300\n",
      "100/100 [==============================] - 0s 624us/step - loss: 50.7450\n",
      "Epoch 259/300\n",
      "100/100 [==============================] - 0s 576us/step - loss: 50.7449\n",
      "Epoch 260/300\n",
      "100/100 [==============================] - 0s 503us/step - loss: 50.7447\n",
      "Epoch 261/300\n",
      "100/100 [==============================] - 0s 568us/step - loss: 50.7446\n",
      "Epoch 262/300\n",
      "100/100 [==============================] - 0s 488us/step - loss: 50.7444\n",
      "Epoch 263/300\n",
      "100/100 [==============================] - 0s 480us/step - loss: 50.7442\n",
      "Epoch 264/300\n",
      "100/100 [==============================] - 0s 584us/step - loss: 50.7441\n",
      "Epoch 265/300\n",
      "100/100 [==============================] - 0s 609us/step - loss: 50.7439\n",
      "Epoch 266/300\n",
      "100/100 [==============================] - 0s 634us/step - loss: 50.7438\n",
      "Epoch 267/300\n",
      "100/100 [==============================] - 0s 551us/step - loss: 50.7436\n",
      "Epoch 268/300\n",
      "100/100 [==============================] - 0s 532us/step - loss: 50.7435\n",
      "Epoch 269/300\n",
      "100/100 [==============================] - 0s 473us/step - loss: 50.7433\n",
      "Epoch 270/300\n",
      "100/100 [==============================] - 0s 502us/step - loss: 50.7432\n",
      "Epoch 271/300\n",
      "100/100 [==============================] - 0s 548us/step - loss: 50.7430\n",
      "Epoch 272/300\n",
      "100/100 [==============================] - 0s 585us/step - loss: 50.7429\n",
      "Epoch 273/300\n",
      "100/100 [==============================] - 0s 692us/step - loss: 50.7427\n",
      "Epoch 274/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 561us/step - loss: 50.7425\n",
      "Epoch 275/300\n",
      "100/100 [==============================] - 0s 697us/step - loss: 50.7424\n",
      "Epoch 276/300\n",
      "100/100 [==============================] - 0s 557us/step - loss: 50.7422\n",
      "Epoch 277/300\n",
      "100/100 [==============================] - 0s 556us/step - loss: 50.7421\n",
      "Epoch 278/300\n",
      "100/100 [==============================] - 0s 479us/step - loss: 50.7419\n",
      "Epoch 279/300\n",
      "100/100 [==============================] - 0s 608us/step - loss: 50.7418\n",
      "Epoch 280/300\n",
      "100/100 [==============================] - 0s 506us/step - loss: 50.7416\n",
      "Epoch 281/300\n",
      "100/100 [==============================] - 0s 514us/step - loss: 50.7415\n",
      "Epoch 282/300\n",
      "100/100 [==============================] - 0s 497us/step - loss: 50.7413\n",
      "Epoch 283/300\n",
      "100/100 [==============================] - 0s 456us/step - loss: 50.7412\n",
      "Epoch 284/300\n",
      "100/100 [==============================] - 0s 558us/step - loss: 50.7410\n",
      "Epoch 285/300\n",
      "100/100 [==============================] - 0s 556us/step - loss: 50.7408\n",
      "Epoch 286/300\n",
      "100/100 [==============================] - 0s 603us/step - loss: 50.7407\n",
      "Epoch 287/300\n",
      "100/100 [==============================] - 0s 542us/step - loss: 50.7405\n",
      "Epoch 288/300\n",
      "100/100 [==============================] - 0s 598us/step - loss: 50.7404\n",
      "Epoch 289/300\n",
      "100/100 [==============================] - 0s 446us/step - loss: 50.7402\n",
      "Epoch 290/300\n",
      "100/100 [==============================] - 0s 449us/step - loss: 50.7401\n",
      "Epoch 291/300\n",
      "100/100 [==============================] - 0s 560us/step - loss: 50.7399\n",
      "Epoch 292/300\n",
      "100/100 [==============================] - 0s 424us/step - loss: 50.7398\n",
      "Epoch 293/300\n",
      "100/100 [==============================] - 0s 514us/step - loss: 50.7396\n",
      "Epoch 294/300\n",
      "100/100 [==============================] - 0s 508us/step - loss: 50.7394\n",
      "Epoch 295/300\n",
      "100/100 [==============================] - 0s 464us/step - loss: 50.7393\n",
      "Epoch 296/300\n",
      "100/100 [==============================] - 0s 516us/step - loss: 50.7391\n",
      "Epoch 297/300\n",
      "100/100 [==============================] - 0s 461us/step - loss: 50.7390\n",
      "Epoch 298/300\n",
      "100/100 [==============================] - 0s 560us/step - loss: 50.7388\n",
      "Epoch 299/300\n",
      "100/100 [==============================] - 0s 687us/step - loss: 50.7387\n",
      "Epoch 300/300\n",
      "100/100 [==============================] - 0s 648us/step - loss: 50.7385\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have shape (26244,) but got array with shape (162,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f49f915540fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_build_relation_graph_with_symertic_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_get_matix_for_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mag/scripts/main.py\u001b[0m in \u001b[0;36mtest_autoencoder\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0;31m# Validate and standardize user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     x, _, _ = self._standardize_user_data(\n\u001b[0;32m-> 1486\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;34m'Error when checking '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    192\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have shape (26244,) but got array with shape (162,)"
     ]
    }
   ],
   "source": [
    "graph = test_build_relation_graph_with_symertic_data()\n",
    "data = test_get_matix_for_autoencoder(graph)\n",
    "test_autoencoder(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
